{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap last lecture\n",
    "- linear averaging dynamics\n",
    "- lazy linear averaging dynamics: time of convergence\n",
    "- wisdowm of crowds: the effect of democracy\n",
    "- linear flow dynamics\n",
    "\n",
    "**Any questions?**\n",
    "\n",
    "# Today's lecture\n",
    "- how to compute left dominant eigenvectors of P using linear flow dynamics\n",
    "- ratio bottlenecks and second dominant eigenvalue\n",
    "- linear averaging dynamics (not lazy): time of convergence\n",
    "- how to compute distributed average using linear averaging dynamics\n",
    "- dynamics with inputs: intervention problems\n",
    "- resistor networks\n",
    "- duality between resistor networks and averaging dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to compute left dominant eigenvectors (invariant distributions) by linear flow dynamics\n",
    "\n",
    "Let $G=(V,E,W)$ be a weighted graph, and $x(t) \\in \\mathrm{R}^{V}$ denote the total mass in the node of the graph.\n",
    "\n",
    "The dynamics of $x(t)$ reads\n",
    "\n",
    "$$\n",
    "x(t+1) = P'x(t),\n",
    "$$\n",
    "\n",
    "where $P$ is the normalized adjacency matrix of the graph and is called in this context the **routing matrix**.\n",
    "The routing matrix has the following interpretation: if $x_j$ is the total mass in node $j$, $P_{ji}$ is the fraction of the mass that will be routed in node $i$ at the next step, i.e.,\n",
    "\n",
    "$$\n",
    "x_i(t+1) = \\sum_{j} P_{ji} x_j(t)\n",
    "$$\n",
    "\n",
    "The equilibria of the dynamics satisfy $x=P'x$, i.e., $x$ is a left dominant eigenvector of $P$.\n",
    "\n",
    "The dynamics will converge to an equilibrium if all the components corresponding to sinks of the condensation graph (i.e., attractive components) are aperiodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(1,2),(2,1),(1,0),(0,2),(3,2),(3,4),(4,5),(5,4),(6,4),(5,6)])\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above has two trapping sets (sinks in the condensation graph), both aperiodic.\n",
    "\n",
    "Let us recall some properties on left dominant eigenvectors of $P$.\n",
    "\n",
    "**Left dominant eigenvectors**: recall that \n",
    "- the eigenvalue 1 has multeplicity (both geometric and algebraic) equal to the number of sinks of the condensation graph;\n",
    "- all the left dominant eigenevctors of $P$ has support on the nodes that belong to the trapping sets of the graph;\n",
    "- dominant eigenvectors whose support belong to one trapping set only are called extremal;\n",
    "- all the dominant eigenvectors can be obtained as a convex combination of extremal dominant eigenvectors.\n",
    "\n",
    "To compute all the dominant eigenvectors, we run the dynamics with a non-zero mass in both the trapping sets of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least a non-zero element in x[0], x[1], x[2] (first trapping set)\n",
    "# at least a non-zero element in x[4], x[5], x[6] (second trapping set)\n",
    "x = np.array([1,0,3,2,3,1,6])\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "for iter in range(100):\n",
    "    x = P.T @ x\n",
    "\n",
    "print(\"x(100):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mass distribution in the trapping sets reaches an equilibrium (because both the trapping sets are aperiodic). \n",
    "Note indeed that eventually all the mass will flow out from non-trapping sets ($x[3] \\to 0$ for large times). Once $x$ approaches zero for all the nodes not belonging to trapping sets, the dynamics in each trapping set becomes independent of the rest of the network. Thus, we can use theoretical results to guarantee that if a trapping set of the graph is aperiodic, then the dynamics on the subgraph will converge to the (unique) invariant distribution of the induced subgraph defined on the trapping set.\n",
    "\n",
    "If the dynamics reaches an equilibrium, the resulting $x^*$ has to be left dominant eigenvector. However, if we run another dynamics with different initial condition we get another left dominant eigenvector..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "print(\"Left dominant eigenvector:\", x/np.sum(x))\n",
    "\n",
    "x = np.array([0,0,1,0,3,1,6])\n",
    "\n",
    "for iter in range(100):\n",
    "    x = P.T @ x\n",
    "\n",
    "print(\"Left dominant eigenvector:\", x/np.sum(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot try an infinite number of initial conditions...\n",
    "\n",
    "To obtain all the dominant eigenvectors, we first obtain the two extremal ones $\\pi^{(1)}$ and $\\pi^{(2)}$, and then combine then by convex combination, i.e.,\n",
    "\n",
    "$$\n",
    "\\pi = \\alpha \\pi^{(1)} + (1-\\alpha) \\pi^{(2)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the two extremal eigenvalue it suffices to isolate the nodes that refer to the trapping set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.zeros(G.number_of_nodes())\n",
    "x1[0:3] = x[0:3]\n",
    "\n",
    "print(\"First extremal dominant eigenvector:\", x1/sum(x1))\n",
    "\n",
    "x2 = np.zeros(G.number_of_nodes())\n",
    "x2[4:7] = x[4:7]\n",
    "\n",
    "print(\"Second extremal dominant eigenvector:\", x2/sum(x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to run a dynamics with non-zero initial condition on a trapping set only, e.g., for the first trapping set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([7,2,1,0,0,0,0])\n",
    "\n",
    "for iter in range(100):\n",
    "    x = P.T @ x\n",
    "\n",
    "print(\"First extremal dominant eigenvector:\", x/np.sum(x))\n",
    "\n",
    "x = np.array([0,0,0,0,3,4,3])\n",
    "\n",
    "for iter in range(100):\n",
    "    x = P.T @ x\n",
    "\n",
    "print(\"Second extremal dominant eigenvector:\", x/np.sum(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio bottleneck (for simple graphs)\n",
    "\n",
    "**Definition**: the ratio bottleneck (for simple graphs) is\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\t\\Phi = \\ & \\underset{\\substack{\\mathcal{U} \\subset \\mathcal{V}: \\\\ 0<w_{\\mathcal{U}} \\le \\frac{1}{2} \\mathbf{1}' w}}{\\min}\n",
    "\t& & \\frac{|\\partial_{\\mathcal{U}}|}{w_{\\mathcal{U}}}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "The ratio bottleneck is a measure of connectedness of the graph, and is related to $\\lambda_2$. The higher $\\lambda_2$ is, the less connected the graph is, the smaller is $\\Phi$, and the slower the convergence is. In particular,\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\Phi^2 \\le 1-\\lambda_2 \\le 2 \\Phi\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: complete graph**\n",
    "\n",
    "The properties of a subset $\\mathcal{U}$ are completeley determined by its cardinality. Let us consider a complete graph with $n$ nodes, and let $\\mathcal{U}_m$ denote an arbitrary subset of $m$ nodes of the complete graph. Its boundary has cardinality $|\\partial_{\\mathcal{U}_m}| = m \\cdot (n-m)$, thus\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\t\\Phi = \\ & \\underset{m \\le n/2}{\\min}\n",
    "\t& & \\frac{m(n-m)}{m(n-1)} \\rightarrow \\frac{1}{2}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "as $n \\to +\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: barbell graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.barbell_graph(5,0)\n",
    "\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G,pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottleneck is clearly to select one of the two complete components of the graph.\n",
    "For that $\\mathcal{U}$,\n",
    "\n",
    "$$\n",
    "|\\partial_{\\mathcal{U}} = 1|, \\quad w_{\\mathcal{U}} = n(n-1)+1,\n",
    "$$\n",
    "\n",
    "where $2n$ is the order of the graph. Thus, for large $n$\n",
    "\n",
    "$$\n",
    "\\Phi = \\frac{1}{n^2-n+1} \\rightarrow 0,\n",
    "$$\n",
    "\n",
    "which implies that $\\lambda_2 \\to 1$ and the convergence is slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: is the convergence always slow? \n",
    "    \n",
    "No, it depends on the initial condition.\n",
    "\n",
    "While $\\lambda_2$ describes a worst-case scenario for the speed of convergence, it might be that for some initial condition the convergence is fast!\n",
    "\n",
    "For instance, let us compare a random initial condition with an initial condition which has a high disagreement along the two components of the bottleneck of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.barbell_graph(150,0)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# Construct lazy P\n",
    "P = P/2 + np.diag(np.ones(G.number_of_nodes()))/2\n",
    "\n",
    "# let us start with random initial condition\n",
    "x = np.random.rand(G.number_of_nodes())>1/2\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.001):\n",
    "    x = P @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "\n",
    "print('Number of iteration for convergence:', t)\n",
    "\n",
    "# let us start with a specific initial condition which maximizes the disagreement along the bottleneck of the graph, i.e.,\n",
    "# a complete subgraph has all zeros, and the second one has all ones.\n",
    "x = np.zeros(G.number_of_nodes())\n",
    "x[0:int(G.number_of_nodes()/2)] = np.ones(int(G.number_of_nodes()/2))\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.0002):\n",
    "    x = P @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "\n",
    "print('Number of iteration for convergence:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though $\\lambda_2 \\to 1$, with a random initial condition the two complete graphs mix the opinions quickly and reach an agreement within the component in a few iterations. On average, both the components tend to opinion $1/2$, which mean that there is no large disagreements between the two components.\n",
    "\n",
    "On the other hand, if a component has opinion $0$ and the other one has opinion $1$, since the two complete components are not well connected, it takes a lot to reach consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to (not lazy) averaging dynamics\n",
    "\n",
    "In lazy dynamics the speed of convergence is described by $\\lambda_2$. In standard averaging dynamics, also $\\lambda_n$ plays a role. We recall indeed that the speed of convergence is described by\n",
    "\n",
    "$$\n",
    "\\lambda := \\max\\{\\lambda_2,|\\lambda_n|\\},\n",
    "$$\n",
    "\n",
    "where $\\lambda_n$ is the smallest eigenvalue of $P$.\n",
    "\n",
    "While $\\lambda_2$ is related to the level of connectedness of the graph, we shall see in a qualititive manner the role of $\\lambda_n$ by doing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us construct a regular graph with 6m nodes, and degree of each node equal to m\n",
    "\n",
    "m = 5\n",
    "G = nx.cycle_graph(6*m)\n",
    "\n",
    "n_nodes = 6*m\n",
    "\n",
    "for n in range(6*m):\n",
    "    for i in range(m):\n",
    "        G.add_edge(n,(6*(i+1)+n-3) % 18)\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "\n",
    "nx.draw(G,pos,with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,v = np.linalg.eig(P)\n",
    "w = w.real\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $-1$ is in the spectrum of $P$, the graph is periodic and the dynamics cannot converge. In fact, one can observe that the graph is bipartite. Thus, the convergence is not guaranteed.\n",
    "\n",
    "Let us now add a single edge to break the periodicity while mantaining the total number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(0,2)\n",
    "G.remove_edge(0,9)\n",
    "\n",
    "nx.draw(G,pos,with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "w,v = np.linalg.eig(P)\n",
    "w = w.real\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is not periodic now. However, $|\\lambda_n| \\sim 1$, which implies that the convergence of the dynamics is slow. On the other hand, $\\lambda_2$ is \"small\" ($\\sim 1/2$), thus the lazy dynamics converges quickly.\n",
    "\n",
    "In some sense, $|\\lambda_n| \\sim 1$ reflects the fact that the graph is almost periodic. Let us see this with an example, by comparing the speed in convergence of the lazy dynamics and the standard dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a larger graph\n",
    "m = 50\n",
    "G = nx.cycle_graph(6*m)\n",
    "\n",
    "G.add_edge(0,2)\n",
    "\n",
    "n_nodes = 6*m\n",
    "\n",
    "for n in range(6*m):\n",
    "    for i in range(m):\n",
    "        G.add_edge(n,(6*(i+1)+n-3) % n_nodes)\n",
    "        \n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# let us start with random initial condition and standard dynamics\n",
    "x0 = np.random.rand(G.number_of_nodes())>1/2\n",
    "x = x0\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.00001):\n",
    "    x = P @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "    if t>100000:\n",
    "        t='inf'\n",
    "        break\n",
    "        \n",
    "print('Number of iterations for convergence of standard dynamics:', t)\n",
    "\n",
    "# same initial condition, lazy dynamics\n",
    "x = x0\n",
    "\n",
    "# Construct lazy P\n",
    "P = P/2 + np.diag(np.ones(G.number_of_nodes()))/2\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.00001):\n",
    "    x = P @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "    if t>100000:\n",
    "        t='inf'\n",
    "        break\n",
    "        \n",
    "print('Number of iterations for convergence of lazy dynamics:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the speed of convergence in the lazy dynamics depends only on the connectivity of the graph ($\\lambda_2$), the speed of convergence in the standard dynamics depends both on the connectivity ($\\lambda_2$) and the periodicity of the graph ($|\\lambda_n|$). The example above shows that the standard averaging dynamics may converge slowly when the graph is a perturbation of a periodic graph, even if the dynamics is well-connected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: distributed computation of average\n",
    "\n",
    "Let the node set describe a set of sensors that are deployed in some region in order to collect measurements of some quantity of interest (for example, the temperature). \n",
    "\n",
    "Assume that these sensors have limited communication and computation capabilities that allow each of them to exchange information only with those other sensors that are close enough in space. \n",
    "\n",
    "Let the graph $G = (V, E)$ describe the pattern of vicinity among the sensors $i$ and $j$ so that there is an undirected link between node $i$ and node $j$ if they can communicate to each other (possibly using link weights decreasing with distance). Then, one can design a distributed algorithm for computing the average of the sensor's measurements based on the averaging dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x_i(0)$ be the measurement of each node. \n",
    "\n",
    "We are interested in designing an iterative distributed algorithm that allows the nodes to compute\n",
    "\n",
    "$$\n",
    "x = \\frac{1}{n}\\sum_i x_i(0)\n",
    "$$\n",
    "\n",
    "**First attempt**: we run a consensus algorithm. Since the graph is undirected, $\\pi_i = \\frac{w_i}{\\sum_j w_j}$. Thus, the algorithm converges to a consensus $\\alpha \\mathbf{1}$ such that\n",
    "\n",
    "$$\n",
    "\\alpha = \\sum_{i} \\frac{w_i}{w} x_i(0),\n",
    "$$\n",
    "\n",
    "which differs from our goal.\n",
    "\n",
    "If each edge knows its degree $w_i$, each node can rescale its initial state, i.e., $y_i(0) = \\frac{x_i(0)}{w_i}$. The consensus algorithm for the variable $y_i$ thus converges to\n",
    "\n",
    "$$\n",
    "\\alpha_y = \\sum_{i} \\frac{w_i}{w} y_i(0) = \\frac{1}{w} \\sum_{i} x_i(0).\n",
    "$$\n",
    "\n",
    "If we assume that each node knows the average degree of the network $\\overline{w}$, thus\n",
    "\n",
    "$$\n",
    "x = \\alpha_y \\frac{w}{n} = \\alpha_y \\overline{w}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Fix node positions on all pictures according to spring layout\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos)\n",
    "\n",
    "n_nodes = len(G)\n",
    "\n",
    "x = np.random.rand(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us run the consensus algorithm for y\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "y = x/degrees\n",
    "\n",
    "for t in range(1000):\n",
    "    y = P @ y\n",
    "\n",
    "print(\"average initial condition:\", np.mean(x))\n",
    "# choose arbitrarly the first node, but all the nodes reach consensus on y\n",
    "print(\"average computed distributively\", y[0] * np.sum(degrees) / n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm works! Unfortunately, requiring that each node knows the average degree of the network is not realistic and is not distributed, because it requires that each node has some global information on the network.\n",
    "\n",
    "However, there exists another way to solve the problem in a distributed manner.\n",
    "\n",
    "We run a second averaging dynamics, with initial condition $z_i(0) = \\frac{1}{w_i}$.\n",
    "\n",
    "This converges to\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to + \\infty} z_i(t) = \\sum_i z_i(0) \\frac{w_i}{w} = \\sum_{i} \\frac{1}{w} = n/w = 1/\\overline{w}\n",
    "$$\n",
    "\n",
    "By combining the two, each node can estimate the average estimate by \n",
    "\n",
    "$$\n",
    "\\frac{\\lim_{t \\to + \\infty} y_i(t)}{\\lim_{t \\to + \\infty} z_i(t)} = \\alpha_y / \\overline{w} = x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us implement this\n",
    "\n",
    "z = 1/degrees\n",
    "\n",
    "for t in range(1000):\n",
    "    z = P @ z\n",
    "\n",
    "print(\"average state:\", np.mean(x))\n",
    "# choose arbitrarly the first node, but all the nodes reach consensus both on y and z\n",
    "print(\"average computed distributively\", y[0] / z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear averaging dynamics with stubborn agents\n",
    "In the second part of the lab we study how to simulate the linear averaging dynamics on graphs in presence of stubborn agents.\n",
    "\n",
    "We focus on the optimal placement problem, which consists of optimally chosing the position of a stubborn node on the graph in order to maximize its influence on the asymptotic outcome of the dynamics.\n",
    "\n",
    "Let us first summarize the theory in presence of stubborn agents.\n",
    "\n",
    "We are given a network, where the agents $V$ are divided in regular agents $R$ and stubborn agents $S$. The regular agents update their opinion $x(t)$ according to the standard DeGroot model, while the stubborn agents do not update their opinion $u(t) \\equiv u$.\n",
    "\n",
    "Let $Q=P|_{R \\times R}$ and $E=P|_{R \\times S}$.\n",
    "\n",
    "Thus, the dynamics for the regular agents read:\n",
    "\n",
    "$$\n",
    "x(t+1) = Qx(t) + Eu.\n",
    "$$\n",
    "\n",
    "Under some assumptions (see the lecture notes from the theoretical perspective) the dynamics converges to \n",
    "\n",
    "$$\n",
    "x^* = (\\mathbf{I}-Q)^{-1}Eu.\n",
    "$$\n",
    "\n",
    "Note that:\n",
    "- the asymptotic state is not a consensus;\n",
    "- the asymptotic state does not depend on the initial opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "We start with implementing the averaging dynamics with stubborn nodes. \n",
    "\n",
    "To illustrate this procedure, we will analyse the following example that involves a $3 \\times 4$ grid graph $\\mathcal G$.\n",
    "\n",
    "First, we construct such graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.generators.lattice.grid_graph(dim=[3,4])\n",
    "n_nodes = len(G)\n",
    "print(\"Number of nodes:\", n_nodes)\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "nx.draw_spectral(G, with_labels=True)\n",
    "\n",
    "print(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dictionary that maps the label of nodes  \n",
    "# (from (0,0) to (2,1)) to their index (from 0 to n_nodes-1)\n",
    "indices = dict()\n",
    "for i in range(n_nodes):\n",
    "    indices[list(G.nodes)[i]] = i\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_iter = 50;\n",
    "    \n",
    "# Stubborn and regular nodes\n",
    "stubborn = [(0,0), (3,2)];\n",
    "stubborn_id = [indices.get(key) for key in stubborn]\n",
    "regular = [node for node in G.nodes if node not in stubborn]\n",
    "regular_id = [id for id in range(n_nodes) if id not in stubborn_id]\n",
    "print(\"Stubborn nodes:\", stubborn, \"\\n\")\n",
    "print(\"Regular nodes:\", regular, \"\\n\")\n",
    "\n",
    "# Input to stubborn nodes\n",
    "u = [0,1]\n",
    "\n",
    "# P matrix\n",
    "A = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "A = A.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(A,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ A\n",
    "\n",
    "# Submatrices\n",
    "# Using ix_ one can construct index arrays that will \n",
    "# index a cross product. \n",
    "# a[np.ix_([1,3],[2,5])] returns the array [[a[1,2] a[1,5]], [a[3,2] a[3,5]]].\n",
    "Q = P[np.ix_(regular_id, regular_id)]\n",
    "E = P[np.ix_(regular_id, stubborn_id)]\n",
    "\n",
    "# Sample a random initial condition for regular nodes\n",
    "ic = np.random.uniform(0,1,len(regular))\n",
    "\n",
    "# Set the initial condition for the dynamics\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn_id,0] = u;\n",
    "x[regular_id,0] = ic;\n",
    "print(\"Initial condition:\", x[:,0], \"\\n\")\n",
    "\n",
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular_id, t] = Q @ x[regular_id, t-1] + E @ x[stubborn_id, t-1]\n",
    "    x[stubborn_id, t] = x[stubborn_id, t-1];\n",
    "\n",
    "x_final = x[:,n_iter-1]\n",
    "for key in indices.keys():\n",
    "    print(key, x_final[indices[key]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(n_nodes):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = np.average(x_final)\n",
    "print(\"Average asymptotic opinion:\", average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the dynamics does not converge to consensus. Moreover, in contrast with averaging without input stubborn nodes, we can verify that the asymptotic equilibrium does not depend on the initial condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample another random initial condition for regular nodes\n",
    "ic = np.random.uniform(0,1,len(regular))\n",
    "\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn_id,0] = u;\n",
    "x[regular_id,0] = ic;\n",
    "print(\"Initial condition:\", x[:,0], \"\\n\")\n",
    "\n",
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular_id, t] = Q @ x[regular_id, t-1] + E @ x[stubborn_id, t-1]\n",
    "    x[stubborn_id, t] = x[stubborn_id, t-1];\n",
    "\n",
    "x_final = x[:,n_iter-1]\n",
    "for key in indices.keys():\n",
    "    print(key, x_final[indices[key]])\n",
    "    \n",
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(n_nodes):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal placement of stubborn nodes\n",
    "Suppose that node $(0,0)$ is stubborn with opinion $u_{(0,0)}=0$. We want to find the optimal position $(i,j)$ of a stubborn node with opinion $1$ in order to maximize the asymptotic average opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple approach is to consider all possible positions $(i,j)$ and pick the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_iter = 50;\n",
    "\n",
    "# We will store final opinion vectors and \n",
    "# average of final opinions in dictionaries\n",
    "# where the key is the position (i,j) of the \n",
    "# 1-stubborn agent\n",
    "final_opinions = dict()\n",
    "average_opinion = dict() \n",
    "\n",
    "\n",
    "for (i,j) in G.nodes:\n",
    "    # Position (0,0) is occupied by the 0-stubborn node\n",
    "    if (i,j)==(0,0):\n",
    "        continue\n",
    "        \n",
    "    # Stubborn and regular nodes\n",
    "    stubborn = [(0,0), (i,j)];\n",
    "    stubborn_id = [indices.get(key) for key in stubborn]\n",
    "    regular = [node for node in G.nodes if node not in stubborn]\n",
    "    regular_id = [id for id in range(n_nodes) if id not in stubborn_id]\n",
    "    print(\"Stubborn nodes:\", stubborn)\n",
    "\n",
    "    # Input to stubborn nodes\n",
    "    u = [0,1]\n",
    "\n",
    "\n",
    "    # P matrix\n",
    "    A = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "    A = A.toarray() # convert A to a numpy array\n",
    "    degrees = np.sum(A,axis=1)\n",
    "    D = np.diag(degrees)\n",
    "    P = np.linalg.inv(D) @ A\n",
    "\n",
    "    # Submatrices\n",
    "    Q = P[np.ix_(regular_id, regular_id)]\n",
    "    E = P[np.ix_(regular_id, stubborn_id)]\n",
    "\n",
    "    # Sample a random initial condition for regular nodes\n",
    "    ic = np.random.uniform(0,1,len(regular))\n",
    "\n",
    "    # Set the initial condition for the dynamics\n",
    "    x = np.zeros((n_nodes,n_iter))\n",
    "    x[stubborn_id,0] = u;\n",
    "    x[regular_id,0] = ic;\n",
    "\n",
    "    for t in range(1,n_iter):\n",
    "        x[regular_id, t] = Q @ x[regular_id, t-1] + E @ x[stubborn_id, t-1]\n",
    "        x[stubborn_id, t] = x[stubborn_id, t-1];\n",
    "\n",
    "    final_opinions[(i,j)] = x[:,n_iter-1]\n",
    "    average_opinion[(i,j)] = np.average(final_opinions[(i,j)])\n",
    "    print(\"Average opinion:\", average_opinion[(i,j)], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the dependence of the average asymptotic opinion on the position of the $1$-stubborn node we can plot the grid graph by setting each node's size and color according to the magnitude of the average asymptotic opinion when the $1$-stubborn is placed in such node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a dummy (0,0) entry to the dictionary\n",
    "# to make its size = n_nodes\n",
    "average_opinion[(0,0)] = 0\n",
    "\n",
    "plt.figure(1, figsize=(7,3))\n",
    "nx.draw(G, \n",
    "        pos = nx.spectral_layout(G),\n",
    "        with_labels=True, \n",
    "        node_size = [np.exp(10*average_opinion[node]) for node in G.nodes],\n",
    "        node_color= [average_opinion[node] for node in G.nodes],\n",
    "        font_size=8,\n",
    "        # node's colors are on the red scale\n",
    "        cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal placements of the 1-stubborn player are the maximizers of the final average opinion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the average opinion values from dict_values to numpy array\n",
    "avg = np.fromiter(average_opinion.values(),dtype=float)\n",
    "\n",
    "optimal_place = [place for place in average_opinion.keys() if average_opinion[place]==np.max(avg)]\n",
    "print(\"Optimal placements:\", optimal_place)\n",
    "\n",
    "print(optimal_place)\n",
    "\n",
    "# print the final opinions under optimal placement\n",
    "opt_final = final_opinions.get(*optimal_place)\n",
    "print(opt_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the asymptotic opinions of the nodes when the stubborn is placed in (1,1)\n",
    "\n",
    "plt.figure(1, figsize=(7,3))\n",
    "nx.draw(G, \n",
    "        pos = nx.spectral_layout(G),\n",
    "        with_labels=True, \n",
    "        node_size = [np.exp(8*opt_final[indices.get(node)]) for node in G.nodes],\n",
    "        node_color= [opt_final[indices.get(node)] for node in G.nodes],\n",
    "        font_size=8,\n",
    "        # node's colors are on the red scale\n",
    "        cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to an old example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(10)\n",
    "G = nx.Graph.to_directed(G)\n",
    "G.remove_edges_from([(0,1),(0,9)])\n",
    "G.add_edge(0,0)\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "n_iter = 100\n",
    "x = np.zeros((10,n_iter))\n",
    "\n",
    "# set initial condition (1,0,0,0,0,0,0,0,0,0)\n",
    "x[0,0] = 1\n",
    "\n",
    "# evolve the states\n",
    "for t in range(1,n_iter):\n",
    "    x[:,t] = P @ x[:,t-1]\n",
    "\n",
    "print(\"Average final opinions:\", np.mean(x[:,n_iter-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(G.number_of_nodes()):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prove that this is equivalent to having node 0 stubborn with opinion 1.\n",
    "\n",
    "Indeed, note that because of the topology of the graph, the opinion of node 0 is not influenced by anyone. The same dynamics can be obtained by assuming that node 0 is stubborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stubborn and regular nodes\n",
    "stubborn = [0];\n",
    "regular = [node for node in G.nodes if node not in stubborn]\n",
    "\n",
    "print(\"Stubborn nodes:\", stubborn, \"\\n\")\n",
    "print(\"Regular nodes:\", regular, \"\\n\")\n",
    "\n",
    "# Input to stubborn nodes\n",
    "u = [1]\n",
    "\n",
    "# Submatrices\n",
    "Q = P[np.ix_(regular, regular)]\n",
    "E = P[np.ix_(regular, stubborn)]\n",
    "\n",
    "# Set the initial condition for the dynamics\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn,0] = u;\n",
    "print(\"Initial condition:\", x[:,0], \"\\n\")\n",
    "\n",
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular, t] = Q @ x[regular, t-1] + E @ x[stubborn, t-1]\n",
    "    x[stubborn, t] = x[stubborn, t-1];\n",
    "\n",
    "x_final = x[:,n_iter-1]\n",
    "print(x_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(G.number_of_nodes()):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same trajectory as before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more general model: overview on Friedkin-Johnsen model\n",
    "The French-DeGroot dynamics can be generalized by taking into account that each agents is not completely regular or completely stubborn. The opinion of each agents is in part due to \"innate\" opinions, and in part due to influence of society.\n",
    "\n",
    "The following opinion dynamics model is known as Friedkin-Johnsen model.\n",
    "Here:\n",
    "- $x_i(t)$ is the opinion of the agent $i$;\n",
    "- $y_i$ is the innate opinion of agent $i$.\n",
    "- $\\alpha_i$ is its level of stubborness, i.e., the level of confidence in his/her opinion $y_i$.\n",
    "\n",
    "The dynamics reads:\n",
    "\n",
    "$$\n",
    "x_i(t+1) = \\alpha_i y_i + (1-\\alpha_i) \\sum_{j} P_{ij} x_j(t).\n",
    "$$\n",
    "\n",
    "If $\\alpha = \\mathbf{0}$, we get the French-DeGroot model without input.\n",
    "\n",
    "If $\\alpha \\in \\{0,1\\}^{V}$, we get the French-DeGroot model with stubborn nodes.\n",
    "\n",
    "As the French-DeGroot model with input, also the Friedkin-Johnsen dynamics converges to a non-consensus state, which depends on $\\alpha, y$, but not on the initial opinions $x(0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resistor networs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given an undirected weighted graph, where the weight $c_{ij}$ denotes the conductance between nodes $i$ and $j$. \n",
    "Let $x$ indicate the node potential distribution, and $\\phi$ denote the current flowing in the network. Ohm's law establish the following relation between current, potential and conductances: \n",
    "\n",
    "$$\n",
    "\\phi_{ab} = c_{ab}(x_a-x_b).\n",
    "$$ \n",
    "\n",
    "We here recall the main instruments to solve electrical network problems: **Series law, Parallel law, Gluing**\n",
    "\n",
    "**Observation**: asymptotical opinions in French-DeGroot model with stubborn is equivalent to potential in resistor network.\n",
    "\n",
    "Indeed, they solve the same equations, i.e., for every regular node (non-stubborn in opinion dynamics, without boundary conditions in electrical problems), \n",
    "\n",
    "$$x_i = \\sum_j P_{ij} x_j$$ \n",
    "\n",
    "We can thus use this equivalence to solve a problem with the most convenient tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: two equivalent problems**\n",
    "\n",
    "**Problem 1**\n",
    "We are given a network $G=(V,E,W)$, where $W$ is the conductance matrix of the network (we consider in this case unweighted graphs. \n",
    "Let $x_0=1, x_4=0$ be the boundary conditions on the potential. Find the potential of the other nodes.\n",
    "\n",
    "**Problem 2**\n",
    "We are given a social network $G=(V,E,W)$. Let $\\{0,4\\}$ the set of stubborn agents, with opinions $u_0 = 0, u_1 = 4$. Find the asymptotic opinions of French-DeGroot dynamics.\n",
    "\n",
    "The solution of the problem is the same. Thus, we can solve only one of the two by using tools from opinion dynamics or electrical network based on what is more convenient for the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(1,2),(2,3),(3,0),(0,4),(1,4),(2,4),(3,4)])\n",
    "\n",
    "pos = {0: (0,0), 1: (2,0), 2: (2,2), 3: (0,2), 4: (1,1)}\n",
    "\n",
    "nx.draw(G,pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 methods for solving the problem**\n",
    "\n",
    "**Method 1**\n",
    "Solve the system of equations $x_i=\\sum_j P_{ij} x_j$ for every regular node $i$. The system has unique solution because the graph is strongly connected.\n",
    "\n",
    "**Method 2**\n",
    "Since the graph is aperiodic, run the French-DeGroot dynamics until convergence.\n",
    "\n",
    "**Method 3**\n",
    "Use Series, parallel, and gluing laws.\n",
    "\n",
    "We skip **Method 1**, let us start with **Method 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "\n",
    "stubborn = [0,4];\n",
    "regular = [node for node in G.nodes if node not in stubborn]\n",
    "\n",
    "print(\"Stubborn nodes:\", stubborn, \"\\n\")\n",
    "print(\"Regular nodes:\", regular, \"\\n\")\n",
    "\n",
    "# Input to stubborn nodes\n",
    "u = [0,1]\n",
    "\n",
    "# Submatrices\n",
    "Q = P[np.ix_(regular, regular)]\n",
    "E = P[np.ix_(regular, stubborn)]\n",
    "\n",
    "# Set the initial condition for the dynamics\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn,0] = u;\n",
    "print(\"Initial condition:\", x[:,0], \"\\n\")\n",
    "\n",
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular, t] = Q @ x[regular, t-1] + E @ x[stubborn, t-1]\n",
    "    x[stubborn, t] = x[stubborn, t-1];\n",
    "\n",
    "x_final = x[:,n_iter-1]\n",
    "print(x_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3**\n",
    "\n",
    "Note that by symmetry x_1 = x_3 ---> **Gluing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.Graph()\n",
    "G1.add_edges_from([(0,1),(1,2),(0,4),(1,4),(2,4)])\n",
    "\n",
    "pos1 = {0: (0,0), 1: (2,0), 2: (2,2), 4: (1,1)}\n",
    "\n",
    "nx.draw(G1,pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have conductancies:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "c_{04} = c_{24} = 1, \\\\\n",
    "c_{01} = c_{12} = c_{14} = 2.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We operate a series composition of edges $(2,4)$ and $(1,2)$, plus a parallel composition of the resulting link with $(1,4)$. The resulting network is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.Graph()\n",
    "G2.add_edges_from([(0,1),(0,4),(1,4)])\n",
    "\n",
    "pos1 = {0: (0,0), 1: (2,0), 4: (1,1)}\n",
    "\n",
    "nx.draw(G2,pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have conductancies:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "c_{04} = 1, \\\\\n",
    "c_{14} = (1/2 + 1)^{-1} + 2 = 8/3, \\\\\n",
    "c_{01} = 2.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The resulting conductance of the series of links $(0,1)$ and $(1,4)$ is $(1/2+3/8)^{-1} = 8/7$.\n",
    "\n",
    "Using the fact that $x_0 = 0, $x_4 = 1$, by Ohm's law, $\\phi_{41}=\\phi_{10}=8/7$.\n",
    "\n",
    "Using again Ohm's law:\n",
    "\n",
    "$$\n",
    "2(x_1-x_0) = \\phi_{10} \\implies x_1 = 8/14 = 4/7 \n",
    "$$\n",
    "\n",
    "Moreover, $x_1 = x_3 = 4/7$.\n",
    "\n",
    "Finally, by Kirchhoff's law on $G1$,\n",
    "\n",
    "$$\n",
    "(x_4 - x_2)C_{24} = (x_2-x_1)C_{12} \\implies x_2 = \\frac{x_4 C_{24} + x_1C_{12}}{C_{24}+C_{12}} = \\frac{1+\\frac{4}{7}\\cdot2}{1+2} = \\frac{5}{7},\n",
    "$$\n",
    "\n",
    "which is equivalent to what obtained by French-DeGroot dynamics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture outline:\n",
    "- more comments opinion dynamics with stubborn agents;\n",
    "- electrical (resistor) networks;\n",
    "- discrete-time Markov chains;\n",
    "- continuous-time Markov chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opinion dynamics with stubborn agents\n",
    "\n",
    "### Back to an old example\n",
    "\n",
    "French-DeGroot dynamics without inputs on a graph with a sink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.cycle_graph(10)\n",
    "G = nx.Graph.to_directed(G)\n",
    "G.remove_edges_from([(0,1),(0,9)])\n",
    "\n",
    "# add a selfloop (0,0), otherwise the outdegree of node 0 is 0 and the matrix D is not well defined\n",
    "G.add_edge(0,0)\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 200\n",
    "# keep track of the trajectory\n",
    "x = np.zeros((10,n_iter))\n",
    "\n",
    "# set initial condition (1,0,0,0,0,0,0,0,0,0)\n",
    "x[0,0] = 1\n",
    "\n",
    "# evolve the states\n",
    "for t in range(1,n_iter):\n",
    "    x[:,t] = P @ x[:,t-1]\n",
    "\n",
    "print(\"Average final opinions:\", np.mean(x[:,n_iter-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(G.number_of_nodes()):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because of the topology of the graph, the opinion of node 0 is not influenced by anyone, thus he maintains his initial opinion (which is 1).\n",
    "\n",
    "The nodes that converge faster are 1 and 9, which are closer to the sink.\n",
    "\n",
    "We can prove that this is equivalent to having node 0 stubborn with opinion 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stubborn and regular nodes\n",
    "stubborn = [0];\n",
    "regular = [node for node in G.nodes if node not in stubborn]\n",
    "\n",
    "print(\"Stubborn nodes:\", stubborn, \"\\n\")\n",
    "print(\"Regular nodes:\", regular, \"\\n\")\n",
    "\n",
    "# Input to stubborn nodes\n",
    "u = [1]\n",
    "\n",
    "# Submatrices\n",
    "Q = P[np.ix_(regular, regular)]\n",
    "E = P[np.ix_(regular, stubborn)]\n",
    "\n",
    "# Set the initial condition for the dynamics\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn,0] = u;\n",
    "print(\"Initial condition:\", x[:,0], \"\\n\")\n",
    "\n",
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular, t] = Q @ x[regular, t-1] + E @ x[stubborn, t-1]\n",
    "    x[stubborn, t] = x[stubborn, t-1];\n",
    "\n",
    "x_final = x[:,n_iter-1]\n",
    "print(x_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(G.number_of_nodes()):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same trajectory as before!\n",
    "\n",
    "**Take-home message**: stubborn nodes are equivalent to regular nodes whose outdegree is 0 (except for selfloops)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resistor networs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given an undirected weighted graph, where the weight $c_{ij}$ denotes the conductance between nodes $i$ and $j$. \n",
    "Let $x$ indicate the potential distribution, and $\\phi$ denote the current flowing in the network. Ohm's law establish the following relation between current, potential and conductances: \n",
    "\n",
    "$$\n",
    "\\phi_{ab} = c_{ab}(x_a-x_b).\n",
    "$$ \n",
    "\n",
    "We here recall the main instruments to solve electrical network problems: **Series law, Parallel law, Gluing**.\n",
    "\n",
    "![figure](reti_elettriche.png)\n",
    "\n",
    "**Observation**: asymptotic opinions in French-DeGroot model with stubborn agents is equivalent to potential in resistor network where the potential of some nodes is fixed a priori.\n",
    "\n",
    "Indeed, they satisfy same equations, i.e., for every regular node (non-stubborn in opinion dynamics, without boundary conditions in electrical problems), \n",
    "\n",
    "$$x_i = \\sum_j P_{ij} x_j$$ \n",
    "\n",
    "We can thus use this equivalence to solve a problem with the most convenient tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: two equivalent problems**\n",
    "\n",
    "**Problem 1**\n",
    "We are given a network $G=(V,E,W)$, where $W$ is the conductance matrix of the network (we consider in this case unweighted graphs). \n",
    "Let $x_0=0, x_4=1$ be the boundary conditions on the potential. Find the potential of the other nodes.\n",
    "\n",
    "**Problem 2**\n",
    "We are given a social network $G=(V,E,W)$. Let $\\{0,4\\}$ the set of stubborn agents, with opinions $u_0 = 0, u_4 = 1$. Find the asymptotic opinions of French-DeGroot dynamics.\n",
    "\n",
    "The solution of the problem is the same. Thus, we can solve only one of the two by using tools from opinion dynamics or electrical network based on what suits better to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(1,2),(2,3),(3,0),(0,4),(1,4),(2,4),(3,4)])\n",
    "\n",
    "pos = {0: (0,0), 1: (2,0), 2: (2,2), 3: (0,2), 4: (1,1)}\n",
    "\n",
    "nx.draw(G,pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 methods for solving the problem**\n",
    "\n",
    "**Method 1**\n",
    "Solve the system of linear equations $x_i=\\sum_j P_{ij} x_j$ for every regular node $i$..\n",
    "\n",
    "**Method 2**\n",
    "Run the French-DeGroot dynamics until convergence.\n",
    "\n",
    "**Method 3**\n",
    "Use Series, parallel, and gluing laws.\n",
    "\n",
    "We skip Method 1, let us start with **Method 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "\n",
    "stubborn = [0,4];\n",
    "regular = [node for node in G.nodes if node not in stubborn]\n",
    "\n",
    "print(\"Stubborn nodes:\", stubborn, \"\\n\")\n",
    "print(\"Regular nodes:\", regular, \"\\n\")\n",
    "\n",
    "# Input to stubborn nodes\n",
    "u = [0,1]\n",
    "\n",
    "# Submatrices\n",
    "Q = P[np.ix_(regular, regular)]\n",
    "E = P[np.ix_(regular, stubborn)]\n",
    "\n",
    "# Set the initial condition for the dynamics\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn,0] = u;\n",
    "print(\"Initial condition:\", x[:,0], \"\\n\")\n",
    "\n",
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular, t] = Q @ x[regular, t-1] + E @ x[stubborn, t-1]\n",
    "    x[stubborn, t] = x[stubborn, t-1];\n",
    "\n",
    "x_final = x[:,n_iter-1]\n",
    "print(\"final opinions:\", x_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3**\n",
    "\n",
    "Note by symmetry that x_1 = x_3 ---> we can operate **Gluing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.Graph()\n",
    "G1.add_edges_from([(0,1),(1,2),(0,4),(1,4),(2,4)])\n",
    "\n",
    "labels = ['2','1','2','2','1']\n",
    "\n",
    "zip_operator = zip(G1.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "plt.subplot(121)\n",
    "nx.draw(G,pos, with_labels=True)\n",
    "plt.subplot(122)\n",
    "nx.draw_networkx_edge_labels(G1,pos,edge_labels = labels)\n",
    "nx.draw(G1,pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new node 1 is the result of gluing 1 and 3.\n",
    "\n",
    "We thus have conductancies:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "c_{04} = c_{24} = 1, \\\\\n",
    "c_{01} = c_{12} = c_{14} = 2.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We operate a series composition of edges $(2,4)$ and $(1,2)$, plus a parallel composition of the resulting link with $(1,4)$. The resulting conductance $c_{14}$ is\n",
    "\n",
    "$$\n",
    "c'_{14} = (c^{-1}_{24}+c_{21}^{-1})^{-1} + c_{14} = (2^{-1}+1^{-1})^{-1} + 2 = 2/3 + 2 = 8/3\n",
    "$$\n",
    "\n",
    "and the resulting network is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.Graph()\n",
    "G2.add_edges_from([(0,1),(0,4),(1,4)])\n",
    "\n",
    "# plot old graph\n",
    "plt.subplot(121)\n",
    "nx.draw_networkx_edge_labels(G1,pos,edge_labels = labels)\n",
    "nx.draw(G1,pos, with_labels=True)\n",
    "\n",
    "# plot new graph\n",
    "plt.subplot(122)\n",
    "\n",
    "labels = ['2','1','8/3']\n",
    "zip_operator = zip(G2.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "nx.draw_networkx_edge_labels(G2,pos,edge_labels = labels)\n",
    "nx.draw(G2,pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have conductancies:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "c_{04} = 1, \\\\\n",
    "c_{14} = (1/2 + 1)^{-1} + 2 = 8/3, \\\\\n",
    "c_{01} = 2.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The resulting conductance of the series of links $(0,1)$ and $(1,4)$ is $(1/2+3/8)^{-1} = 8/7$.\n",
    "\n",
    "Using the fact that $x_0 = 0, x_4 = 1$, by Ohm's law, $\\phi_{41}=\\phi_{10}=8/7$.\n",
    "\n",
    "Using again Ohm's law:\n",
    "\n",
    "$$\n",
    "2(x_1-x_0) = \\phi_{10} \\implies x_1 = 8/14 = 4/7 \n",
    "$$\n",
    "\n",
    "Moreover, by symmetry, $x_3 = x_1 = 4/7$.\n",
    "\n",
    "Finally, by Kirchhoff's law on $G1$,\n",
    "\n",
    "$$\n",
    "(x_4 - x_2)C_{24} = (x_2-x_1)C_{12} \\implies x_2 = \\frac{x_4 C_{24} + x_1C_{12}}{C_{24}+C_{12}} = \\frac{1+\\frac{4}{7}\\cdot2}{1+2} = \\frac{5}{7},\n",
    "$$\n",
    "\n",
    "which is equivalent to what obtained by French-DeGroot dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential\n",
    "x = np.array([0,4/7,5/7,4/7,1])\n",
    "\n",
    "print('potential:', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential is equivalent to asymptotic opinions in French-DeGroot dynamics with in input.\n",
    "\n",
    "We can thus apply techniques from FDG dynamics (e.g., iterative implementation of the dynamics) to find the potential in electrical network, or apply techinques from electrical networks (e.g., series and parallel composition, gluing, Ohm's law) to find asymptotic opinions in FDG dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov chains\n",
    "In this part of the Lab we learn how to simulate discrete and continuous time Markov chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first example: Random Walks on graphs and the flow dynamics\n",
    "In this section we study a first example of discrete time Markov chain, which is the simple random walk on a graph, and we analyse the connection between random walks and the flow dynamics.\n",
    "\n",
    "To explore such connections we first learn how to simulate a random walk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Random Walk\n",
    "\n",
    "A random walker on a graph $\\mathcal G$ is an agent that starts at the initial time $0$ at some node and at each time moves from the current position to a neighboring one, chosen with uniform probability (this can be generalized).\n",
    "\n",
    "To learn how to simulate a random walk, here we consider the example of a $n \\times n$ chessboard with a single knight on it. \n",
    "1. We construct a network $G$ with all knight's possible moves. In this network nodes represent chessboard locations and an edge between two locations is present if the knight is admitted to move from one to another. (Note that the resulting graph is undirected).\n",
    "2. We implement a simulation of the knight's random walk on the chessboard network $G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, rand "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Knight's Network\n",
    "\n",
    "Here we define function `GenerateKnightNetwork` that constructs the knight's network. \n",
    "It exploits two auxiliary functions, `ApplyLegalMoves` and `isLegalPos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the graph representing the knigth network.\n",
    "# Return both the graph object G and the pos dictionary\n",
    "# for drawing G.\n",
    "\n",
    "def GenerateKnightNetwork(boardSize):\n",
    "    # undirected graph G will store the knight's network\n",
    "    G = nx.Graph()\n",
    "    # when drawing G, the pos dictiornary describes the position on \n",
    "    # a boardsize x boardsize grid where to place nodes\n",
    "    pos = {}\n",
    "    \n",
    "    # we assign position to nodes\n",
    "    # we have boardSize x boardSize nodes\n",
    "    for row in range(boardSize):\n",
    "        for column in range(boardSize):\n",
    "            node_id = row + column*boardSize\n",
    "            # pos[node_id] are the (x,y) coordinates of node node_id \n",
    "            # on a square grid of side boardSize\n",
    "            pos[node_id] = np.array([1.0*row/boardSize, 1.0*column/boardSize])\n",
    "            \n",
    "            # compute the (row,column) of neighboring position to the\n",
    "            # current one, i.e., positions on the chessoboard reachable\n",
    "            # by applying legal moves\n",
    "            neigh_pos = ApplyLegalMoves(row, column, boardSize)\n",
    "            # for each neigbhoring position, compute the id and add\n",
    "            # a link in G from current position node_id to neigh_id\n",
    "            for p in neigh_pos:\n",
    "                neigh_id = p[0] + p[1]*boardSize\n",
    "                G.add_edge(node_id, neigh_id)\n",
    "    return G, pos\n",
    "\n",
    "\n",
    "# Apply the knight's legal moves to the current position to construct\n",
    "# neighboring nodes in the knight's graph\n",
    "\n",
    "def ApplyLegalMoves(x,y,boardSize):\n",
    "    # will store the neighboring nodes\n",
    "    new_positions = []\n",
    "    \n",
    "    # offsets describe the effect of the knight's legal moves\n",
    "    # on the current position's row and column\n",
    "    offsets = [(-1,-2),(-1,2),(-2,-1),(-2,1),\n",
    "                   ( 1,-2),( 1,2),( 2,-1),( 2,1)]\n",
    "    \n",
    "    # for each legal move, compute the new position's row and column\n",
    "    for off in offsets:\n",
    "        new_x = x + off[0]\n",
    "        new_y = y + off[1]\n",
    "        \n",
    "        # if the new position doesn't exceed the boardsize,\n",
    "        # accept it as legal\n",
    "        if isLegalPos(new_x,boardSize) and isLegalPos(new_y,boardSize):\n",
    "            new_positions.append((new_x,new_y))\n",
    "         \n",
    "    return new_positions\n",
    "\n",
    "# Determines if the position obtained applying a move is legal,\n",
    "# i.e. if it is inside the chessboard\n",
    "def isLegalPos(x,boardSize):\n",
    "    if x >= 0 and x < boardSize:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to generate an example of the knight's network, with a specified boardsize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boardSize = 8\n",
    "# use position dictionary returned by the function GenerateKnightNetwork\n",
    "(G,pos) = GenerateKnightNetwork(boardSize)\n",
    "nx.draw(G,pos, with_labels=True, node_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate the Random Walk Process\n",
    "Now that we have the graph $G$ representing the knight's network, we can simulate the knight's random walk on it. \n",
    "\n",
    "The walk starts at some given node and it can either terminate after a specified number of steps or when it first returns to the starting node.\n",
    "\n",
    "At each step, the walker is at some node `xi` and has to decide which node to visit next. \n",
    "\n",
    "In this simple version of the random walk, he does it by choosing a neighbor of the current node uniformly at random.\n",
    "More formally, he looks at row `xi` of the normalized weight matrix $P$ of the graph $G$ and interprets the numbers on that row as the probability of visiting the corresponding nodes next, given that he currently is at `xi`.\n",
    "\n",
    "To simulate the random walk we define the function `RandomWalk`, which allows to specify the graph $G$ on which the walk takes place, the starting node and the stopping criterion.\n",
    "\n",
    "**Remark 1**: the `RandomWalk` function is independent on the specific example we are studying. In other words, it allows to simulate any simple random walk on any **unweighted** graph $G$, since it only exploits the general features of the stochastic process at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulates a random walk on the graph G, starting from node xi.\n",
    "# if till_first_return = True the random walk stops the first time\n",
    "# it returns to the starting node xi.\n",
    "# Otherwise, it goes on for num_steps steps.\n",
    "\n",
    "def RandomWalk(G, xi, num_steps, till_first_return = False):\n",
    "    # nodeSeq stores the sequence of visited nodes\n",
    "    nodeSeq = []\n",
    "    nodeSeq.append(xi)\n",
    "    \n",
    "    # if the walk ends at the first return to xi\n",
    "    if till_first_return:\n",
    "        # stores the initial position to check if the \n",
    "        # walk returns to it\n",
    "        x_init = xi\n",
    "        \n",
    "        # no upper bound on the number of steps\n",
    "        while True:\n",
    "            # compute the next visited node xi by chosing uniformly\n",
    "            # at random a neighbor of the current one\n",
    "            xi = choice(G.adj[xi],1)[0]     \n",
    "            nodeSeq.append(xi)\n",
    "            \n",
    "            # check if the walk has returned to the starting node\n",
    "            # if so, end the walk\n",
    "            if xi == x_init:\n",
    "                return nodeSeq\n",
    "    \n",
    "    # if the walk ends after num_steps steps\n",
    "    else:\n",
    "        for i in range(num_steps):\n",
    "            xi = choice(G.adj[xi],1)[0]      \n",
    "            nodeSeq.append(xi)\n",
    "        return nodeSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can implement RandomWalk with different stopping criteria, or using non-uniform transition probability distributions (for weighted graph, as we shall see later on).\n",
    "\n",
    "As a first experiment, we simulate a simple random walk on $G$ with $10$ steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a random walk on G \n",
    "nodeSeq = RandomWalk(G, xi=0, num_steps=10, till_first_return=False)\n",
    "edgeSeq = [(nodeSeq[i-1], nodeSeq[i]) for i in range(1,len(nodeSeq))]\n",
    "\n",
    "# Draw G and represent the random walk by colouring the edge sequence\n",
    "# first draw all nodes and links\n",
    "nx.draw(G, pos)\n",
    "# then, on the previous picture, add node labels and highlight the edge sequence\n",
    "nx.draw(G, pos, with_labels=True, edgelist = edgeSeq, edge_color='blue', node_color='red', width=2)\n",
    "\n",
    "print(\"Node sequence:\", nodeSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a random walk on G that stops at the first return time\n",
    "# note that if till_first_return = True, 'num_steps' is negligible\n",
    "nodeSeq = RandomWalk(G, xi=0, num_steps=1, till_first_return=True)\n",
    "edgeSeq = [(nodeSeq[i-1], nodeSeq[i]) for i in range(1,len(nodeSeq))]\n",
    "\n",
    "# Draw G and represent the random walk by colouring the edge sequence\n",
    "# first draw all nodes and links\n",
    "nx.draw(G, pos)\n",
    "# then, on the previous picture, add node labels and highlight the edge sequence\n",
    "nx.draw(G, pos, with_labels=True, edgelist = edgeSeq, edge_color='blue', node_color='red', width=2)\n",
    "\n",
    "# if the node sequence is not deducible from the plot, you can print the nodeSeq\n",
    "print(\"Node sequence:\", nodeSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a random walk on G with 200 steps\n",
    "nodeSeq = RandomWalk(G, xi=0, num_steps=200, till_first_return=False)\n",
    "edgeSeq = [(nodeSeq[i-1], nodeSeq[i]) for i in range(1,len(nodeSeq))]\n",
    "\n",
    "# Draw G and represent the random walk by colouring the edge sequence\n",
    "# first draw all nodes and links\n",
    "nx.draw(G, pos)\n",
    "# then, on the previous picture, add node labels and highlight the edge sequence\n",
    "nx.draw(G, pos, with_labels=True, edgelist = edgeSeq, edge_color='blue', node_color='red', width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even with a larger number of steps some of the nodes may not be visited!\n",
    "\n",
    "**Question**: do you think that all the nodes are the same probability of being visited?\n",
    "\n",
    "To answer this question, we need to relate random walks to flow dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walks and the Flow Dynamics\n",
    "\n",
    "The random walk and the flow dynamics are deeply connected. Indeed, if we describe the position of the walker on $G$ at time $t$ with a random variable $x(t)$, the variable's probability distribution evolves according to the flow dynamics:\n",
    "\n",
    "$$\n",
    "\\pi(t+1) = P'\\pi(t)\n",
    "$$\n",
    "\n",
    "or more explicitly\n",
    "\n",
    "$$\n",
    "\\pi_j(t+1) = \\sum_{i \\in \\mathcal V} P_{ij}\\pi_i(t),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\pi_i(t) = \\mathbf{P}\\{x(t)=i\\}.\n",
    "$$\n",
    "\n",
    "Moreover, one can use a random walk to estimate the invariant measure $\\pi$ of the graph $G$ (assume here $G$ is strongly connected). Indeed, by the Katz theorem, the fraction of time spent by the walker on each node tends to the node's value in the invariant measure $\\pi$ as the length of the walk increases.\n",
    "\n",
    "The following section shows how to compute empirical frequencies and how to compare them with the inviariant distribution of $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empirical frequencies and invariant distribution\n",
    "The empirical frequencies are the fractions of total walk time that each node of G is visited in the random walk. \n",
    "\n",
    "They can be represented by an histogram as follows.\n",
    "\n",
    "We simulate random walks starting at each node of $G$, and we keep trace of the sequence of visited nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nodeSeq: list to store all random walks\n",
    "nodeSeq = []\n",
    "\n",
    "# simulate one random walk for each initial node in G\n",
    "for xi in range(G.number_of_nodes()):\n",
    "    # list.extend extends the list by appending all the items from an iterable\n",
    "    nodeSeq.extend(RandomWalk(G, xi, 100))\n",
    "    \n",
    "# plt.hist computes and draws the histogram of nodeSeq. We have one bin for each node,\n",
    "# so each bin width is 1 and the number of observations in each bin equals the number\n",
    "# of visits to the correspnding node. \n",
    "# Since density=True, the return element will be the counts normalized \n",
    "# to form a probability density.\n",
    "h = plt.hist(nodeSeq, bins = G.number_of_nodes(), density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use empirical frequencies to approximate the invariant measure of $G$, we have to construct a long random walk. As an example, here we run a random walk with $10000$ steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodeSeq: list to store all random walks\n",
    "nodeSeq = []\n",
    "\n",
    "# simulate one random walk for each initial node in G\n",
    "for xi in range(G.number_of_nodes()):\n",
    "    # list.extend extends the list by appending all the items from an iterable\n",
    "    nodeSeq.extend(RandomWalk(G, xi, 10000))\n",
    "    \n",
    "# plt.hist computes and draws the histogram of nodeSeq. We have one bin for each node,\n",
    "# so each bin width is 1 and the number of observations in each bin equals the number\n",
    "# of visits to the correspnding node. \n",
    "# Since density=True, the return element will be the counts normalized \n",
    "# to form a probability density.\n",
    "h = plt.hist(nodeSeq, bins = G.number_of_nodes(), density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequencies are now more smooth, and look not uniform, as expected. Let us compare frequencies with the invariant distribution of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a \"long\" random walk\n",
    "\n",
    "nodeSeq = RandomWalk(G, 0, 100000, False)\n",
    "\n",
    "# Compute empirical frequencies\n",
    "\n",
    "frequencies = np.zeros(len(G))\n",
    "# count the visits to each node\n",
    "for node in nodeSeq:\n",
    "    frequencies[node] += 1\n",
    "# normalize the counts to obtain frequencies\n",
    "frequencies /= len(nodeSeq)\n",
    "print(\"Frequencies:\", frequencies, \"\\n\")\n",
    "\n",
    "# compute the invariant distribution\n",
    "# let us check before the sorting of the nodes\n",
    "print(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the nodes\n",
    "H = nx.Graph()\n",
    "H.add_nodes_from(sorted(G.nodes(data=True)))\n",
    "H.add_edges_from(G.edges(data=True))\n",
    "\n",
    "print(H.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P matrix\n",
    "A = nx.adjacency_matrix(H) # -> return type is scipy.sparse.csr_matrix\n",
    "A = A.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(A,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ A\n",
    "\n",
    "# Compute invariant distribution\n",
    "values,vectors = np.linalg.eig(P.T)\n",
    "index = np.argmax(values.real)\n",
    "pi = vectors[:,index].real\n",
    "pi = pi/np.sum(pi)\n",
    "\n",
    "print(\"pi=\", pi, \"\\n\")\n",
    "\n",
    "print(\"frequencies=\", frequencies, \"\\n\")\n",
    "\n",
    "# Evaluate the approximation error by computing the norm of\n",
    "# the difference between the empirical frequencies and the \n",
    "# invariant measure\n",
    "error = np.linalg.norm(frequencies-pi)\n",
    "print(\"Error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** Note how important the invariant distribution is. So far, it appeared in many different contexts:\n",
    "- centrality measures in social networks;\n",
    "- consensus value in averaging dynamics;\n",
    "- limit of linear flow dynamics;\n",
    "- invariant probability distributions in random walks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Consider the graph shown in the following picture:\n",
    "![Exgraph](graph1.png)\n",
    "\n",
    "**Remark 2**: for nodes without out-going links, follow the convention and add a self-loop.\n",
    "\n",
    "1. For each node of $G$, simulate the simple random walk starting from that node. What do you observe? How can you justify your observations?\n",
    "2. Study the graph $G$ and compute its invariant measures. Can you see any relation with the behavior of the random walk?\n",
    "3. Substitute the link (5,1) with the link (1,5) and repeat the analysis performed at point 1. and 2. What topological property of the graph has changed? How does this reflect on the random walk process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete time Markov chains\n",
    "We already saw an example of discrete time Markov chain: the random walk on the knight's network.\n",
    "\n",
    "In general, every discrete time Markov chain can be interpreted as a random walk on a weighted directed graph. So, in the general case, transition probabilities from each node to its neighbors are not uniformly distributed.\n",
    "\n",
    "To better understand this notion, we analyse the following example.\n",
    "\n",
    "![DMCgraph](discreteMC.png)\n",
    "\n",
    "1. Construct the directed graph G with weights as shown in the picture.\n",
    "2. Compute the invariant probability distribution vector by computing the leading eigenvector of P'\n",
    "3. Simulate a random walk starting from node 1 on the graph for n = 1000, 2000, 5000, 10000 steps. Determine the fraction of the steps the walk has been in each node i. Compare this with the invariant distribution. What do you observe?\n",
    "\n",
    "**Hint:** you can adopt the function RandomWalk by modifying the choice of the next node to visit according to the fact that the transition probability is not uniform.\n",
    "\n",
    "4. What happens with your estimate of $\\pi$ if you remove node 5 and all links connected to it from the graph and add a self loop of weight 1 to node 6?\n",
    "5. Compute the expected hitting time $\\mathbb{E}_j[T_S]$, $\\forall j \\in R = \\mathcal V \\setminus \\mathcal S$, for the set $S = \\{2, 5\\}$ analytically.\n",
    "6. For every node i, simulate several times a random walk on G that begins in node i and stops when it comes back to it. Use this simulation to estimate the expected return time, $\\mathbb{E}_i[T_i^+]$. Compare this estimate with the expected return times obtained analytically from the expected hitting times.\n",
    "\n",
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "# add weighted edges\n",
    "G.add_weighted_edges_from([(1,3,1),(1,4,2),(2,1,1),(3,1,7),(3,6,3),(4,2,1),(4,3,4),(5,5,2),(5,3,1),(6,5,1)])\n",
    "\n",
    "# define a new graph with sorted nodes\n",
    "H = nx.DiGraph()\n",
    "H.add_nodes_from(sorted(G.nodes(data=True)))\n",
    "H.add_edges_from(G.edges(data=True))\n",
    "\n",
    "nx.draw(H,with_labels=True)\n",
    "\n",
    "# Compute P matrix\n",
    "A = nx.adjacency_matrix(H) # -> return type is scipy.sparse.csr_matrix\n",
    "A = A.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(A,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ A\n",
    "\n",
    "n_nodes = H.number_of_nodes()\n",
    "\n",
    "print(\"P:\", P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If node 5 is removed, node 6 is a sink node. Hence, all random walks will eventually reach this node so that the estimate of the invariant measure will converge to $\\pi =[0, 0, 0, 0, 1]$. You can check this by simulating the random walk on the modified graph.\n",
    "\n",
    "The interpretation for this is that as the random walks hits 6, it cannot escape. Thus, from there on, it will visit 6 forever. In the limit of infinite $t$, the fraction of time spent in node 6 tends to 1. This is coeherent with the fact that invariant distribution centrality in a graph has support only on nodes that belong to trapping set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. The expected hitting times  $\\hat{x}= (\\mathbb{E}_i[T_S])_{i \\in R}$ for the set $S$ and for all nodes $i \\in R = \\mathcal V \\setminus S$ can be computed by solving the system of equations\n",
    "\n",
    "$$\n",
    "\\hat{x} = \\mathbf{1} + \\hat{P}\\hat{x},\n",
    "$$ \n",
    "\n",
    "where $\\hat{P}$ is obtained from $P$ (the normalized weight matrix of the graph) by removing the rows and columns corresponding to the nodes in the set $S$.\n",
    "\n",
    "More explicitly, the expected hitting times can be expressed as\n",
    "\n",
    "$$\n",
    "\\hat{x} = (I - \\hat{P})^{-1} \\mathbf{1}\n",
    "$$\n",
    "\n",
    "**Remark**: note that $(I - \\hat{P})$ is invertible if and only if $V \\setminus S$ has at least a link pointing to $S$. Indeed, if $(I - \\hat{P})$ is not invertible. the random walk starting from nodes in $V \\setminus S$ cannot hit nodes in $S$, and the hitting time explode.\n",
    "\n",
    "Thus, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set S and the remaining nodes R\n",
    "# Subtract -1 because indexes go from 0 to 5 and nodes from 1 to 6\n",
    "S = [1, 4] # refer to nodes [2,5]\n",
    "R = [node for node in range(n_nodes) if node not in S]\n",
    "\n",
    "# Restrict P to R x R to obtain hat(P)\n",
    "hatP = P[np.ix_(R, R)]\n",
    "\n",
    "# solve the linear system to obtain hat(x)\n",
    "# np.linalg.solve solves a linear matrix equation given\n",
    "# the coefficient matrix and the dependent variable values\n",
    "hatx = np.linalg.solve((np.identity(n_nodes-2)-hatP),np.ones(n_nodes-2))\n",
    "# map node to position of node in hatx\n",
    "map = {0: 0, 2: 1, 3: 2, 5: 3}\n",
    "\n",
    "# define the hitting times to the set S\n",
    "# hitting time is 0 if the starting node is in S\n",
    "hitting_s = np.zeros(n_nodes)\n",
    "# hitting time is hat(x) for nodes in R\n",
    "for r in R:\n",
    "    hitting_s[r] = hatx[map[r]]\n",
    "\n",
    "print(\"hitting times:\", hitting_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for node 6 the expected hitting time is 1, because its only outneighbour belongs to $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. To compute expected return times analytically, recall that they can be caracterized by\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_i[T_i^+] = 1 + \\sum_{j} P_{ij} \\mathbb{E}_j[T_i]\n",
    "$$\n",
    "\n",
    "where $\\mathbb{E}_j[T_i]$ is the expected hitting time to the set $S={i}$ starting from $j$.\n",
    "\n",
    "So, for computing $\\mathbb{E}_i[T_i^+]$, one can:\n",
    "- set $S=\\{i\\}$\n",
    "- compute the expected hitting times to $S$, $\\mathbb{E}_j[T_i]$, $\\forall j \\in V\\setminus \\{i\\}$ (as done in point 5)\n",
    "- apply the linear relation $\\mathbb{E}_i[T_i^+] = 1 + \\sum_{j} P_{i,j} \\mathbb{E}_j[T_i]$\n",
    "\n",
    "Instead, an estimation of the expected return time $\\mathbb{E}_i[T_i^+]$, $\\forall i$, is obtained by simulating random walks that start at $i$ and end at the first return (you can use `RandomWalk(G, xi=i, num_steps = 'inf', till_first_return = True)`)\n",
    "\n",
    "Implement and compare the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Time Markov Chains\n",
    "\n",
    "In CTMC, the time is not discrete ($t=0,1,\\ldots$) but it flows in a continuum ($ t \\geq 0$).\n",
    "\n",
    "The random process still describes the evolution of a state variable $x$ inside a discrete state space $\\mathcal X$ with a graph structure.\n",
    "A graph $G =(\\mathcal X, \\Lambda)$ with nodes $\\mathcal X$ and weight matrix $\\Lambda$ describes possible transitions between nodes/states.\n",
    "\n",
    "Transitions now happen at random time instants that are decided by the tick of a so called \"Poisson clock\". A Poisson clock is characterized by the property that the time elapsed between any two of\n",
    "its consecutive ticks is an independent random variable with exponential distribution with a specified rate.\n",
    "\n",
    "**Remark 3**:\n",
    "to simulate continuous time Markov chains the following fact will be useful.\n",
    "To simulate a Poisson clock with rate $r$, one must simulate the time between two consecutive ticks, which we denote $t_{next}$. We can compute $t_{next}$ as\n",
    "$$ t_{next} = - \\frac{\\ln(u)}{r}$$\n",
    "where $u$ is a random variable with uniform distribution, $u \\in \\mathcal{U}(0,1)$.\n",
    "\n",
    "\n",
    "### Modelling Continuous time Markov chains\n",
    "There are two equivalent ways of modelling CTMCs.\n",
    "\n",
    "**1st approach**\n",
    "1. you define a unique \"global\" Poisson clock with an appropriate rate $\\omega^* = \\max_i(\\omega_i)$ where $\\omega_i= \\sum_j \\Lambda_{ij}$\n",
    "2. when you are at node $i$ and **the global clock ticks**, either you jump to a neighbor $j$ with probability $Q_{ij} = \\frac{\\Lambda_{ij}}{\\omega_{*}}, \\; i \\neq j$ or you stay in the same node (no transition) with probability $Q_{ii} = 1 - \\sum_{i \\neq j} Q_{ij}$\n",
    "\n",
    "In this approach, the continuous time is \"discretized\" using a global clock, while the matrix Q describes the jumps. For this reason the matrix Q is called jump chain of the CTMC.\n",
    "\n",
    "**2nd approach**\n",
    "1. each node $i$ is equipped with its own Poisson clock with rate $\\omega_i= \\sum_j \\Lambda_{ij}$.\n",
    "2. when you are at node $i$ and **the clock of that node ticks**, you jump to a neighbor $j$ with probability  $P_{ij} = \\frac{\\Lambda_{ij}}{\\omega_i}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Suppose that the weather can be modelled as a continuous-time Markov chain, with state space $\\mathcal{X} = \\{sunny,rainy, cloudy,snowy\\}$. Let the transition rates be\n",
    "\n",
    "![transitionRates](transitionMatrix.png)\n",
    "\n",
    "1. The probability distribution $\\bar{\\pi}(t)$ of the CTMC $X(t)$ with transition rate matrix $\\Lambda$ is defined as\n",
    "\n",
    "$$\n",
    "\\bar{\\pi}_i(t) = \\mathbb P(X(t) = i), \\quad i \\in \\mathcal X \\,.\n",
    "$$\n",
    "\n",
    "It evolves according to the equation\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt} \\bar{\\pi}(t) = -L'\\bar{\\pi}(t)\n",
    "$$\n",
    "\n",
    "where $L= diag(w) - \\Lambda$, with $w = \\Lambda \\mathbf{1}$.\n",
    "\n",
    "Thus, invariant probability vector are eigenvector of $L'$ corresponding to eigenvalue $0$. It can also be proven that $\\bar{\\pi}$ is the left dominant eigenvector of $Q$, where $Q$ is defined as\n",
    "\n",
    "$$\n",
    "Q_{ij} = \\frac{\\Lambda_{ij}}{\\omega_{*}}, \\; i \\neq j \\quad Q_{ii} = 1 - \\sum_{i \\neq j} Q_{ij}\n",
    "$$\n",
    "\n",
    "with $\\omega = \\Lambda \\mathbf{1}$ and $\\omega_{*}=\\max_i \\omega_i$.\n",
    "\n",
    "Compute the invariant probability vector $\\bar{\\pi}$ of the CTMC by determining the leading eigenvector of the matrix $Q'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "Lambda = [\n",
    "[0, 1/30, 1/15, 1/60],\n",
    "[1/60, 0, 1/10, 1/100],\n",
    "[1/25, 1/10, 0, 1/50],\n",
    "[1/100, 1/10, 1/10, 0]]\n",
    "w = np.sum(Lambda, axis=1)\n",
    "w_star = np.max(w)\n",
    "Q = Lambda/w_star \n",
    "# add the diagonal part\n",
    "Q = Q + np.diag(np.ones(len(w))-np.sum(Q,axis=1))\n",
    "\n",
    "values,vectors = np.linalg.eig(Q.T)\n",
    "index = np.argmax(values.real)\n",
    "pi_bar = vectors[:,index].real\n",
    "pi_bar = pi_bar/np.sum(pi_bar)\n",
    "print(\"pi_bar=\", pi_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Simulate the continuous-time Markov chain starting from sunny weather. Do this following the two different approaches:\n",
    "\n",
    "**a)** 1st approach, i.e., using global clock with rate $\\omega^* = \\max_i{\\omega_i}$ and the conditional probability matrix $Q$.\n",
    "\n",
    "**b)** 2nd approach, i.e., using a rate-$\\omega_i$ clock in each node $i$ and the conditional probability matrix $P$.\n",
    "\n",
    "In both cases:\n",
    "- plot the trajectory for the first 20 jumps,\n",
    "- use the simulation to estimate $\\bar{\\pi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st approach: global clock with rate w_star and matrix Q\n",
    "\n",
    "# set the number of steps in the simulation\n",
    "n_steps = 1000\n",
    "# pos will keep trace of the visited states\n",
    "pos = np.zeros(n_steps, dtype=int)\n",
    "# we start from state 0\n",
    "pos[0] = 0\n",
    "# transition_times will store the time instants at which\n",
    "# jumps/transitions happen\n",
    "transition_times = np.zeros(n_steps)\n",
    "# the random time to wait for the next transition\n",
    "# is drawn according to its distribution, discussed in Remark 2\n",
    "# NOTE: in the formula for t_next we use w_star, the rate of the\n",
    "# \"global\" Poisson clock\n",
    "t_next = -np.log(np.random.rand())/w_star\n",
    "\n",
    "# Compute the cumulative sums of the rows of Q\n",
    "# for ex., if a = np.array([[1,2,3],\n",
    "#                         [4,5,6]])\n",
    "# np.cumsum(a, axis=1) gives array([[ 1,  3,  6],\n",
    "#                                   [ 4,  9, 15]])\n",
    "Q_cum = np.cumsum(Q, axis=1)\n",
    "\n",
    "for i in range(1,n_steps):\n",
    "    # the next state to visit will be extracted according to the probabilities\n",
    "    # stored in the row of Q corresponding to the current state.\n",
    "    # In general, to extract a value pos[i] in (0,...,num_states-1) according to the discrete\n",
    "    # distribution Q[pos[i-1],:], you can extract a random number in [0,1] and compare it with \n",
    "    # the cumulative sums Q_cum[pos[i-1]]. You then pick the first (smallest) state for which\n",
    "    # the cumulative sum is grater than the random number.\n",
    "    pos[i] = np.argwhere(Q_cum[pos[i-1]] > np.random.rand())[0]\n",
    "    # store the time instant of the current transition\n",
    "    transition_times[i] = transition_times[i-1] + t_next\n",
    "    # compute the waiting time to the next transition\n",
    "    t_next = -np.log(np.random.rand())/w_star\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the trajectory for the first 20 jumps\n",
    "plt.plot(transition_times[0:20], pos[0:20], 'bo')\n",
    "plt.title('Trajectory for the first 20 jumps')\n",
    "\n",
    "# Estimate pi\n",
    "\n",
    "pi_estimate = np.zeros(4)\n",
    "# We have the time instants of all transitions, we now compute time intervals.\n",
    "# np.diff computes the n-th discrete difference of a vector.\n",
    "# Here we set n=1 to compute first difference, which is given by \n",
    "# intervals[i] = transition_times[i+1] - transition_times[i].\n",
    "# We also provide a value to  append to transition_times prior to performing the difference\n",
    "# so that we can compute also the last interval: \n",
    "# transition_times[-1] + t_next is the end of the time horizon.\n",
    "intervals = np.diff(transition_times, n=1, append = transition_times[-1] + t_next)\n",
    "\n",
    "# for each state in the state space\n",
    "for state in range(4):\n",
    "    # identify the steps when we visited that state during the process\n",
    "    visits = np.argwhere(pos == state)\n",
    "    # the estimate of the invariant measure for that state is equal to the\n",
    "    # time spent on the state divided the total time of the process\n",
    "    pi_estimate[state] = np.sum(intervals[visits])/(transition_times[-1] + t_next)\n",
    "    \n",
    "print(\"Estimate of pi_bar:\", pi_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd approach: local clocks with rates w_i and matrix P\n",
    "\n",
    "# contruct the P matrix (instead of Q) and clock rates w\n",
    "w = np.sum(Lambda, axis=1)\n",
    "D = np.diag(w)\n",
    "P = np.linalg.inv(D) @ Lambda\n",
    "\n",
    "# set the number of steps in the simulation\n",
    "n_steps = 1000\n",
    "# pos will keep trace of the visited states\n",
    "pos = np.zeros(n_steps, dtype=int)\n",
    "# we start from state 0\n",
    "pos[0] = 0\n",
    "# transition_times will store the time instants at which\n",
    "# jumps/transitions happen\n",
    "transition_times = np.zeros(n_steps)\n",
    "# the random time to wait for the next transition\n",
    "# is drawn according to its distribution, discussed in Remark 2\n",
    "# NOTE: in the formula for t_next we use the rate of the clock of \n",
    "# the current state, in this case w[0].\n",
    "t_next = -np.log(np.random.rand())/w[0]\n",
    "\n",
    "# Compute the cumulative sums of the rows of P\n",
    "P_cum = np.cumsum(P, axis=1)\n",
    "\n",
    "for i in range(1,n_steps):\n",
    "    # the next state to visit will be extracted according to the probabilities\n",
    "    # stored in the row of P corresponding to the current state.\n",
    "    pos[i] = np.argwhere(P_cum[pos[i-1]] > np.random.rand())[0]\n",
    "    # store the time instant of the current transition\n",
    "    transition_times[i] = transition_times[i-1] + t_next\n",
    "    # compute the waiting time to the next transition\n",
    "    # NOTE: we use the rate w[pos[i]] of the clock of the current position\n",
    "    t_next = -np.log(np.random.rand())/w[pos[i]]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the trajectory for the first 20 jumps\n",
    "plt.plot(transition_times[0:20], pos[0:20], 'bo')\n",
    "plt.title('Trajectory for the first 20 jumps')\n",
    "\n",
    "# Estimate pi\n",
    "\n",
    "pi_estimate = np.zeros(4)\n",
    "\n",
    "intervals = np.diff(transition_times, n=1, append = transition_times[-1] + t_next)\n",
    "for node in range(4):\n",
    "    visits = np.argwhere(pos == node)\n",
    "    pi_estimate[node] = np.sum(intervals[visits])/(transition_times[-1] + t_next)\n",
    "print(\"Estimate of pi_bar:\", pi_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. An ice-cream shop’s profit depends on the weather. Their profit per time unit is given by the following function\n",
    "\n",
    "$$\n",
    "f(X) = \\begin{cases} \n",
    "10 & \\text{if X = sunny}\\\\\n",
    "2 & \\text{if X = cloudy}\\\\\n",
    "1 & \\text{if X = rainy}\\\\\n",
    "0 & \\text{if X = snowy}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Simulate how the profit grows with time. Compute the average profit, both from the simulation and from the stationary distribution $\\bar{\\pi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of profit growth\n",
    "# I choose to simulate the CTMC following the first approach\n",
    "\n",
    "# set the number of steps in the simulation\n",
    "n_steps = 1000\n",
    "# payoff values corresponding to each state\n",
    "payoff = [10, 2, 1, 0]\n",
    "\n",
    "pos = np.zeros(n_steps, dtype=int)\n",
    "pos[0] = 0\n",
    "transition_times = np.zeros(n_steps)\n",
    "# since I'm following the first simulation approach, here I divide by the rate\n",
    "# w_star of the global clock\n",
    "t_next = -np.log(np.random.rand())/w_star\n",
    "# we define a profit variable, which stores the comulative profit up to\n",
    "# the current time. For the first interval, which is t_next long, \n",
    "# the profit grows by payoff[pos[0]]*t_next\n",
    "profit = payoff[pos[0]]*t_next\n",
    "\n",
    "Q_cum = np.cumsum(Q, axis=1)\n",
    "\n",
    "# we evolve the process as done before, increasing at each step the total profit\n",
    "for i in range(1,n_steps):\n",
    "    pos[i] = np.argwhere(Q_cum[pos[i-1]] > np.random.rand())[0]\n",
    "    transition_times[i] = transition_times[i-1] + t_next\n",
    "    # compute the waiting time to the next transition\n",
    "    # NOTE: we use the rate w[pos[i]] of the clock of the current position\n",
    "    t_next = -np.log(np.random.rand())/w_star\n",
    "    # during the next interval, which is t_next long, the process will be in state\n",
    "    # pos[i] and the profit will grow by payoff[pos[i]]*t_next\n",
    "    profit = profit + payoff[pos[i]]*t_next\n",
    "    \n",
    "# the average profit is estimated as the overall profit obtained along the\n",
    "# simulation divided by the total time of the process\n",
    "average_profit = profit/(transition_times[-1] + t_next)\n",
    "print(\"Average profit\", average_profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the average payoff of the invariant distribution, computed as \n",
    "\n",
    "$$\n",
    "\\bar{f} = \\sum_{X \\in \\mathcal X} f(X)\\bar{\\pi}_X\n",
    "$$\n",
    "\n",
    "The two estimates should be equivalent as $t$ grows large because of ergodic theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next lecture we will apply these tools to study epidemics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

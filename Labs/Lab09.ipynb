{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epidemics\n",
    "\n",
    "## Exercise 2: absorbing probabilities in SIR dynamics on ring graph\n",
    "\n",
    "In SIR dynamics there are multiple absorbing states (every disease-free state is absorbing). Eventually, the Markov process will reach a disease-free state with probability 1. Instead of computing the absorbing time for a disease-free state, we here ask for every $k \\le n$ what is the probability that the Markov process is absorbed in a state with $n-k$ susceptible agents and $k$ recovered agents. This indicates how large the outbreak was.\n",
    "\n",
    "Let us work with a ring graph, and assume that only one node is infected at the initial time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that all the nodes that get infected (i.e., are either infected or recovered) belong to a connected set. Therefore, the boundary between infected and recovered nodes is at most 2. \n",
    "\n",
    "We identify the states of the process by two scalar indicators, $I$ and $B$:\n",
    "- $I$ now denotes the total number of agents that have been infected from the beginning of the process;\n",
    "- $B$ is number of links between susceptibles and infected agents. Every state is identified through a pair $(I,B)$. \n",
    "\n",
    "Since we are not asking the hitting times, but only the absorbing probabilities we can work with the corresponding jump process where the time $t \\in \\{0,1,2,...\\}$ is discrete.\n",
    "\n",
    "Note that because of the topology of the graph, there are only two types of transitions:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "I(t+1) = I(t) + 1 \\\\\n",
    "B(t+1) = B(t)\n",
    "\\end{cases}\n",
    "\\quad \\quad \\quad\n",
    "\\begin{cases}\n",
    "I(t+1) = I(t) \\\\\n",
    "B(t+1) = B(t)-1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The continuous-time Markov process in the space $(I,B)$ is\n",
    "\n",
    "![figure](continuous_ring-1.png)\n",
    "\n",
    "where the red nodes are the only absorbing states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested only in the absorbing probabilities, we can construct the associated jump chain.\n",
    "\n",
    "**Remark**: there is a slight abuse of notation in the graph, because if all the nodes have been infected, the boundary $B$ must be 0. Here, (N,2) indicates that none of the nodes on the boundary recover before infecting the adjacent node.\n",
    "\n",
    "![figure](discrete_ring-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $p_i$ denote the probability that the outbreak size is $i$. It is straighforward to notice that\n",
    "\n",
    "$$\n",
    "p_1 = \\frac{1}{2\\beta+1}.\n",
    "$$\n",
    "\n",
    "For $n>i>1$, it is necessary that the first node infects a second node (probability $2\\beta/(2\\beta+1)$). For a given $i$, there are multiple paths (specifically, $i-1$ paths) from configuration $(2,2)$ to $(i,0)$, each of them with probability\n",
    "\n",
    "$$\n",
    "\\left(\\frac{\\beta}{\\beta+1}\\right)^{i-2} \\left(\\frac{1}{\\beta+1}\\right)^2.\n",
    "$$\n",
    "\n",
    "Thus, \n",
    "\n",
    "$$\n",
    "p_i = \\frac{2\\beta}{2\\beta+1} \\cdot (i-1) \\cdot \\left(\\frac{\\beta}{\\beta+1}\\right)^{i-2} \\left(\\frac{1}{\\beta+1}\\right)^2.\n",
    "$$\n",
    "\n",
    "For $p_n$ there are $n-2$ paths with probability $\\left(\\frac{\\beta}{\\beta+1}\\right)^{n-2} \\left(\\frac{1}{\\beta+1}\\right)$ and $1$ path with probability $\\left(\\frac{\\beta}{\\beta+1}\\right)^{n-2}$.\n",
    "\n",
    "Putting all together,\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "p_1 = \\frac{1}{2\\beta+1} \\\\\n",
    "p_i = \\frac{2\\beta}{2\\beta+1} \\cdot (i-1) \\cdot \\left(\\frac{\\beta}{\\beta+1}\\right)^{i-2} \\left(\\frac{1}{\\beta+1}\\right)^2 \\quad 1<i<n \\\\\n",
    "p_n = \\frac{2\\beta}{2\\beta+1} \\cdot \\left((n-2) \\left(\\frac{\\beta}{\\beta+1}\\right)^{n-2} \\left(\\frac{1}{\\beta+1}\\right) + \\left(\\frac{\\beta}{\\beta+1}\\right)^{n-2} \\right)\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE RESULT\n",
    "\n",
    "# X: number of infected nodes\n",
    "# Y: probability\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 100\n",
    "beta = 10\n",
    "\n",
    "p = np.zeros(n+1)\n",
    "\n",
    "p[0] = 0\n",
    "p[1] = 1/(2*beta+1)\n",
    "\n",
    "for i in range(2,n):\n",
    "    p[i] = (i-1)*(2*beta)/(2*beta+1)*(beta/(beta+1))**(i-2)/(beta+1)**2\n",
    "    \n",
    "p[n] = (2*beta)/(2*beta+1) * ((n-2)*(beta/(beta+1))**(n-2)/(beta+1)+(beta/(beta+1))**(n-2))\n",
    "\n",
    "x = range(n+1)\n",
    "\n",
    "plt.plot(x[1:n+1],p[1:n+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limits**:\n",
    "- $\\beta \\to 0^+$: $p_1 \\to 1$;\n",
    "- $\\beta \\to +\\infty$: $p_n \\to 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "beta = 0.01\n",
    "\n",
    "p = np.zeros(n+1)\n",
    "\n",
    "p[0] = 0\n",
    "p[1] = 1/(2*beta+1)\n",
    "\n",
    "for i in range(2,n):\n",
    "    p[i] = (i-1)*(2*beta)/(2*beta+1)*(beta/(beta+1))**(i-2)/(beta+1)**2\n",
    "    \n",
    "p[n] = (2*beta)/(2*beta+1) * ((n-2)*(beta/(beta+1))**(n-2)/(beta+1)+(beta/(beta+1))**(n-2))\n",
    "\n",
    "x = range(n+1)\n",
    "\n",
    "plt.plot(x[1:n+1],p[1:n+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "beta = 1000\n",
    "\n",
    "p = np.zeros(n+1)\n",
    "\n",
    "p[0] = 0\n",
    "p[1] = 1/(2*beta+1)\n",
    "\n",
    "for i in range(2,n):\n",
    "    p[i] = (i-1)*(2*beta)/(2*beta+1)*(beta/(beta+1))**(i-2)/(beta+1)**2\n",
    "    \n",
    "p[n] = (2*beta)/(2*beta+1) * ((n-2)*(beta/(beta+1))**(n-2)/(beta+1)+(beta/(beta+1))**(n-2))\n",
    "\n",
    "x = range(n+1)\n",
    "\n",
    "plt.plot(x[1:n+1],p[1:n+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game theory\n",
    "\n",
    "### Theory Recap\n",
    "\n",
    "A **game** in strategic form is a triplet $\\left(\\mathcal V, \\mathcal A, \\{u_i\\}_{i \\in \\mathcal V}\\right)$ where:\n",
    "- $\\mathcal V$ is the finite set of **players**\n",
    "- $\\mathcal A$ is the set of **actions** available to each player. Actions $x_i \\in \\mathcal A$ chosen  by each player are collected in a vector $x = (x_1,x_2, \\ldots, x_n)$ called **configuration** of the game. We denote the set of all configurations by $\\mathcal X = \\mathcal A^{\\mathcal V}$.\n",
    "- for each player $i \\in \\mathcal V$, the utility function $u_i: \\mathcal X \\rightarrow \\mathbb{R}$ describes the **payoff** the player gets in each configuration: the utility of a player depends on its own action but also on the actions of other players.\t\n",
    "\n",
    "To each player $i \\in \\mathcal V$ we associate a **best response** function, which gives, for each configuration of the other players, the best action for $i$ (i.e., the actions that maximize its utility)\n",
    "$$\n",
    "\\mathcal B_i(x_{-i})= \\arg\\max_{x_i \\in \\mathcal A} u_i(x_i,x_{-i})\n",
    "$$\n",
    "\n",
    "A **Nash equilibrium** is a configuration $x^* \\in \\mathcal X$ such that\n",
    "$$\n",
    "x_i^* \\in \\mathcal B_i (x^*_{-i}), \\quad i \\in \\mathcal V\n",
    "$$\n",
    "\n",
    "A game is **potential** if there exists a potential function $\\Phi: \\mathcal X \\rightarrow \\mathbb{R}$ which describes the way the utility function of each player changes when that player unilaterally varies its action. That is, $\\forall i \\in \\mathcal V$, $\\forall x,y \\in \\mathcal X$\n",
    "$$\n",
    "x_{-i}=y_{-i} \\implies u_i(y)-u_i(x) = \\Phi(y)-\\Phi(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete time best response dynamics\n",
    "In this section we present and analyze a first game-theoretic learning process, the discrete time best response dynamics.\n",
    "\n",
    "Consider a game $\\left(\\mathcal V, \\mathcal A, \\{u_i\\}_{i \\in \\mathcal V}\\right)$. \n",
    "\n",
    "The **discrete-time asynchronous best response dynamics** is a Markov chain $X(t)$ with state space $\\mathcal X= \\mathcal A^{\\mathcal V}$ coinciding with the configuration space of the game.\n",
    "At time instant $t$, when the chain is in $X(t)$, one player $i$ is selected uniformly at random in $\\mathcal V$ and she changes her action to a best response chosen uniformly at random in the set $B_i(X(t)_{-i})$.\n",
    "\n",
    "In other words, the best response dynamics is random walk on the transition graph $\\mathcal G_{B}$, i.e., the graph with nodes corresponding to configurations $\\mathcal X=\\mathcal A^{\\mathcal V}$ and links $(x,y)$ from configurations $x$ and $y$ that differ in exactly one entry $i$ if and only if $y_i \\in B_i(x_{-i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Rock-Scissor-Paper game\n",
    "The Rock-Scissor-Paper game is a two-player symmetric game with action set $\\mathcal A =\\{R, S, P\\}$ and utility matrix\n",
    "\n",
    "![utility-matrix](RSP-utility.png)\n",
    "\n",
    "1. Write a function that implements the best response correspondence for both players.\n",
    "2. Does the game admit Nash equilibria?\n",
    "3. Is the game potential?\n",
    "4. Consider the best response dynamics for the RSP game. Plot the transition graph $\\mathcal G_{B}$.\n",
    "5. Simulate the (discrete time) best response dynamics and estimate the invariant probability distribution $\\pi$.\n",
    "6. Compute and plot the condensation graph of $\\mathcal G_{B}$.\n",
    "7. Compute analytically the invariant distribution $\\pi$ of the best response dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Write a function that implements the best response for both players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define action vector\n",
    "# we identify actions with numbers: R->0, S->1, P->2\n",
    "actions = np.array([0,1,2])\n",
    "\n",
    "# Define utility matrix\n",
    "# first index is the player whose utility is being computed 0=first/row player,\n",
    "# 1=second/column player,\n",
    "# second index is the first player action 0=R, 1=S, 2=P,\n",
    "# third index is the second player action 0=R, 1=S, 2=P\n",
    "utility = np.array([[[0, 1, -1],\n",
    "                     [-1, 0, 1],\n",
    "                     [1, -1, 0]],\n",
    "                    [[0, -1, 1],\n",
    "                     [1, 0, -1],\n",
    "                     [-1, 1, 0]]\n",
    "                   ])\n",
    "\n",
    "print(utility)\n",
    "\n",
    "\n",
    "# Best response function for 2 player games \n",
    "def best_response(player, configuration):\n",
    "    # if player == 1, other_player = 0 (and viceversa)\n",
    "    other_player = 1-player\n",
    "    other_action = configuration[other_player]\n",
    "    if player == 0:\n",
    "        # if player == 0, player 0 looks at the action of player 1 (other_action) and chooses BR (2nd index)\n",
    "        return [np.argmax(utility[player, :, other_action])]\n",
    "    if player == 1:\n",
    "        # if player == 1, player 1 looks at the action of player 0 (other_action) and chooses BR (3nd index)\n",
    "        return [np.argmax(utility[player, other_action, :])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. Does the game admit Nash equilibria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Compute all game's configurations\n",
    "# product function computes the cartesian product of actions with itself\n",
    "# returns an iterator of tuples of actions\n",
    "configurations = list(product(actions, repeat=2))\n",
    "print(\"Configurations:\", configurations, \"\\n\")\n",
    "\n",
    "nash_list = []\n",
    "\n",
    "# we cycle over configurations:\n",
    "# each configuration is a Nash unless there exists (at least) one player who\n",
    "# is not playing a best response to the configuration of other players\n",
    "for configuration in configurations:\n",
    "    is_nash = True\n",
    "    for player in [0,1]:\n",
    "        if configuration[player] not in best_response(player,configuration):\n",
    "            is_nash = False\n",
    "            break\n",
    "    if is_nash:\n",
    "        nash_list.append(configuration)\n",
    "        \n",
    "if len(nash_list) != 0:\n",
    "    print(\"The game admits the following Nash equilibria\", nash_list)\n",
    "else:\n",
    "    print(\"The game does not posses Nash equilibria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game does not posses any Nash equilibrium. In each configuration at least one player has an incentive in changing is current action to a best response, which gives him utility $+1$. There are no configurations where both players have utility $+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. Is the game potential?\n",
    "\n",
    "If a finite game (i.e., a  game with a finite configuration set) is potential, then the set of its Nash equilibria is non-empty as it contains the maxima of the potential function $\\Phi$.\n",
    "The RSP game does not posses Nash equilibria, so it is not potential (otherwise Weierstrass' theorem would be violated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4. Consider the best response dynamics for the RSP game. Plot the transition graph $\\mathcal G_{B}$ (i.e., the graph with nodes corresponding to configurations $\\mathcal X=\\mathcal A^{\\mathcal V}$ and links $(x,y)$ between configurations $x$ and $y$ that differ in exactly one entry $i$ if and only if $y_i \\in B_i(x_{-i})$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# transition_graph is a directed graph\n",
    "transition_graph = nx.DiGraph()\n",
    "# nodes of transition_graph are configurations\n",
    "transition_graph.add_nodes_from(configurations)\n",
    "\n",
    "# we visit each configuration x and add links to neighboring configurations.\n",
    "# Neighboring configurations y of x are those that differ in exactly one entry,\n",
    "# the action of a single player i, and such that y_i is a best response to\n",
    "# x_i for player i\n",
    "for configuration in configurations:\n",
    "    for player in [0,1]:\n",
    "        for other_action in actions:\n",
    "            # selects other action in best response, but no selfloops\n",
    "            if other_action != configuration[player] and other_action in best_response(player,configuration):\n",
    "                other_config = list(configuration)\n",
    "                other_config[player] = other_action\n",
    "                other_config = tuple(other_config)\n",
    "                transition_graph.add_edge(configuration,other_config)\n",
    "                \n",
    "pos = nx.spring_layout(transition_graph)\n",
    "nx.draw(transition_graph, pos=pos, with_labels=True)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transition graph has nodes corresponding to the $9$ game configurations and directed links which represent admissible transitions for the best response dynamics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5. Simulate the (discrete time) best response dynamics and estimate the invariant probability distribution $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, rand \n",
    "\n",
    "# Simulates the best response dynamics as a random walk on the transition graph G\n",
    "# starting from node xi.\n",
    "# if till_first_return = True the random walk stops the first time\n",
    "# it returns to the starting node xi.\n",
    "# Otherwise, it goes on for num_steps steps.\n",
    "\n",
    "def RandomWalk(G, xi, num_steps, till_first_return = False):\n",
    "    # nodeSeq stores the sequence of visited nodes\n",
    "    nodeSeq = []\n",
    "    nodeSeq.append(xi)\n",
    "    \n",
    "    # if the walk ends at the first return to xi\n",
    "    if till_first_return:\n",
    "        # stores the initial position to check if the \n",
    "        # walk returns to it\n",
    "        x_init = xi\n",
    "        \n",
    "        while True:\n",
    "            # compute the next visited node xi by chosing uniformly\n",
    "            # at random a neighbor of the current one\n",
    "            neighbors = list(G.neighbors(xi))\n",
    "            index = choice(len(neighbors),1)[0] \n",
    "            xi = neighbors[index] \n",
    "            nodeSeq.append(xi)\n",
    "            \n",
    "            # check if the walk has returned to the starting node\n",
    "            # if so, end the walk\n",
    "            if xi == x_init:\n",
    "                return nodeSeq\n",
    "    \n",
    "    # if the walk ends after num_steps steps\n",
    "    else:\n",
    "        for i in range(num_steps):\n",
    "            neighbors = list(G.neighbors(xi))\n",
    "            index = choice(len(neighbors),1)[0] \n",
    "            xi = neighbors[index]\n",
    "            nodeSeq.append(xi)\n",
    "        return nodeSeq\n",
    "\n",
    "# Simulate the BR dynamics \n",
    "nodeSeq = RandomWalk(transition_graph, xi=(0,0), num_steps=100, till_first_return=False)\n",
    "edgeSeq = [(nodeSeq[i-1], nodeSeq[i]) for i in range(1,len(nodeSeq))]\n",
    "\n",
    "# Draw G and represent the random walk by colouring the edge sequence\n",
    "# first draw all nodes and links\n",
    "nx.draw(transition_graph, pos)\n",
    "# then, on the previous picture, add node labels and highlight the edge sequence\n",
    "nx.draw(transition_graph, pos, with_labels=True, edgelist = edgeSeq, edge_color='blue', node_color='red', width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dynamics starts at configuration (R,R) (represented by (0,0)) and after one step it exit from it. Then it continue cycling over best response cycle $(0,2) \\to (1,2) \\to (1,0) \\to (2,0) \\to (2,1) \\to (0,1) \\to (0,2)$. In particular, it never goes back to $(0,0)$ and $(1,1),(2,2)$ are never visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esitimate the invariant measure pi of the BR dynamics by \n",
    "# simulating a \"long\" random walk\n",
    "\n",
    "nodeSeq = RandomWalk(transition_graph, (0,0), 1000, False)\n",
    "\n",
    "# Compute empirical frequencies\n",
    "\n",
    "# Define a dictionary to store frequencies of visit to each node and initialize each frequency to 0\n",
    "frequencies = {node:0 for node in transition_graph.nodes}\n",
    "# count the visits to each node\n",
    "for node in nodeSeq:\n",
    "    frequencies[node] += 1\n",
    "# transform dict values to a np.array\n",
    "frequencies = list(frequencies[node] for node in transition_graph.nodes) \n",
    "frequencies = np.array(frequencies, dtype=\"double\")\n",
    "# normalize the counts to obtain frequencies\n",
    "frequencies /= len(nodeSeq)\n",
    "print(\"Frequencies:\", frequencies, \"\\n\")\n",
    "\n",
    "# Print the indices of nodes where pi is positive\n",
    "print(\"The approximate invariant distribution is supported on nodes:\")\n",
    "for index,node in enumerate(transition_graph.nodes):\n",
    "    if frequencies[index]>0:\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximate invariant distribution appears to be supported on nodes $\\{(0,0),(0,1),(0,2),(1,0),(1,2),(2,0),(2,1)\\}$ of the transition graph. However, the measure of node $(0,0)$ is negligible with respect to that of $(0,1),(0,2),(1,0),(1,2),(2,0),(2,1)$, which are almost equal to each other. Actually, the little weight associated to node $(0,0)$ appears to depend on the fact that it has been visited once since it is the starting point of the chain. We guess that when the length on the walk tends to infinity the weight associated to node $(0,0)$ vanishes and the approximation of $\\pi$ is supported and uniformly distributed on $\\{(0,1),(0,2),(1,0),(1,2),(2,0),(2,1)\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 6. Compute and plot the condensation graph of $\\mathcal G_{B}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(transition_graph)\n",
    "nx.draw(CG, with_labels=True)\n",
    "print(dict(CG.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condensation graph is shown above, where the hypernode $0$ contains all configurations except for $(R,R), (S,S), (P,P)$ (the ones that correspond to a draw). More precisely, the hypernode $0$ contains the $6$-cycle $(0,2) \\to (1,2) \\to (1,0) \\to (2,0) \\to (2,1) \\to (0,1) \\to (0,2)$. The hypernodes $1,2,3$ instead contain the singletons $(R,R), (S,S), (P,P)$. The condensation graph contains only one sink, that is $s_{\\text{transition_graph}} = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Compute analytically the invariant distribution $\\pi$ of the best response dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the invariant probability distribution is supported on the nodes contained in the unique sink of the condensation graph. The subgraph corresponding to such sink is balanced (all nodes have in-degree $1$ and out-degree $1$, so the sink is $1$-regular), then the extremal invariant probability distribution supported on that sink is obtained by normalizing the out-degree vector. In this way we find that $\\pi_x = 1/6$, for $x \\in \\{RS, RP, SR, SP, PR, PS\\}$ and $\\pi_x = 0$ for $x \\in \\{RR, SS, PP\\}$.\n",
    "\n",
    "We can check that this is correct with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P matrix\n",
    "A = nx.adjacency_matrix(transition_graph) # -> return type is scipy.sparse.csr_matrix\n",
    "A = A.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(A,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ A\n",
    "\n",
    "# Compute invariant distribution\n",
    "values,vectors = np.linalg.eig(P.T)\n",
    "index = np.argmax(values.real)\n",
    "pi = vectors[:,index].real\n",
    "pi = pi/np.sum(pi)\n",
    "print(\"pi=\", pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous time best response dynamics\n",
    "In this section we present the continuous time best response dynamics, which is the continuous time analog of the process presented in the previous section.\n",
    "\n",
    "\n",
    "Consider a game $\\left(\\mathcal V, \\mathcal A, \\{u_i\\}_{i \\in \\mathcal V}\\right)$. \n",
    "\n",
    "The **continuous-time asynchronous best response dynamics** is a continuous time Markov chain $X(t)$ with state space $\\mathcal X= \\mathcal A^{\\mathcal V}$ coinciding with the configuration space of the game and transition rate matrix $\\Lambda$ as follows: \n",
    "\n",
    "$\\Lambda_{xy} = 0$ for every two configurations $x, y \\in \\mathcal X$ that differ in more\n",
    "than one entry, and\n",
    "\n",
    "$$\n",
    "\\Lambda_{xy} = \\begin{cases}\n",
    "|B_i(x_{-i})|^{-1} \\quad &\\text{if} \\quad y_i \\in B_i(x_{-i}) \\\\\n",
    "0 \\quad &\\text{if} \\quad y_i \\notin B_i(x_{-i})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "for every two configurations $x, y \\in \\mathcal X$ differing in entry $i$ only, i.e., such that\n",
    "$x_i \\neq y_i$ and $x_{-i} = y_{-i}$.\n",
    "\n",
    "**Proposition**: consider a potential game, and let $\\mathcal{N}$ the set of the Nash equilibria. Then, the best response dynamics $X(t)$ is such that, for every distribution of the initial configuration $X(0)$, the best response dynamics converges to $\\mathcal{N}$ in finite time with probability 1. \n",
    "\n",
    "**Remark**: Convergence is insured to a particular subset of NE, that is the one consisting of the nodes of all the sink connected components of the underlying transition graph of the Markov process. In the sequel we denote such subset as $\\mathcal{N}_\\infty$: it is a trapping set and actually the largest trapping set inside $\\mathcal{N}$. We call $\\mathcal{N}_\\infty$ the set of recurrent Nash equilibria. Notice that in those special cases when $\\mathcal{N}_\\infty$ coincides with $\\text{argmax}(\\mathcal{X})$, we actually have that the BR dynamics converges to the subset of Nash equilibria consisting of the maxima of the potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous time BRD for network games\n",
    "\n",
    "Network games are games where players are associated to nodes of a graph $\\mathcal G$ that describes the interactions among them. In particular, for each player $i\\in\\mathcal V$ and for each couple of configurations $x,y\\in\\mathcal A^{\\mathcal V}$ such that $x_j=y_j$ for each $j\\in\\ N_i\\cup\\{i\\}$ it holds that\n",
    "\n",
    "$$u_i(x)=u_i(y)$$\n",
    "\n",
    "This means that the utility of each player only depends on the actions of its neighbors in the graph $\\mathcal G$.\n",
    "\n",
    "\n",
    "Given an unweighted undirected graph $\\mathcal G=(\\mathcal V,\\mathcal E,W)$ we can construct a network game on it by setting the playersâ€™ utilities to coincide with the weighted sum of the payoffs of the same symmetric two-player game played by the player simultaneously with her neighbors.\n",
    "\n",
    "Specifically, for a symmetric two-player game with action set $\\mathcal A$ and utility function $\\varphi(x_1, x_2)$ we define the network game $(\\mathcal V, \\mathcal A, \\{u_i\\}_{i \\in \\mathcal V} )$ by setting the utility of every player $i \\in \\mathcal V$ as\n",
    "$$\n",
    "u_i(x) = \\sum_{j \\in \\mathcal V} W_{ij}\\varphi(x_i,x_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary coordination game is a symmetric $2 \\times 2$-game with action set $\\mathcal A = \\{0,1\\}$ with payoff matrix $\\varphi$\n",
    "\n",
    "|   | 0   | 1   |\n",
    "|---|-----|-----|\n",
    "| **0** | a,a | d,c |\n",
    "| **1** | c,d | b,b |\n",
    "\n",
    "where $a > c$ and $b > d$. The inequalities above imply that the best response for each player is to copy the action of the other player.\n",
    "\n",
    "It is a potential game with potential $\\phi$\n",
    "\n",
    "|   | 0   | 1   |\n",
    "|---|-----|-----|\n",
    "| **0** | a-c | 0 |\n",
    "| **1** | 0 | b-d |\n",
    "\n",
    "Consider the **network coordination game**, obtained combining binary coordination games on a complete graph.\n",
    "\n",
    "Recall that such network game is potential with potential function $\\Phi$\n",
    "\n",
    "$$\n",
    "\\Phi(x) = \\frac{1}{2} \\sum_{i,j} W_{ij} \\phi(x_i,x_j) .\n",
    "$$\n",
    "\n",
    "1. Simulate the dynamics when the coordination game has the same utility value for coordination of action 0 and action 1 respectively, i.e., $a=b=1$ and $c=d=0$ (this is called **majority game**). Run the simulation a few times and plot the potential function as a function of time. What do you observe?\n",
    "\n",
    "**Hint**: you need to fix the best response function to deal with more than 2 players. To do this it is useful to define a Python function to represent the utility functions of the network game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next lecture we will analyze best response and noisy best response dynamics in potential games emphasizing the differences between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An overview on learning dynamics**: note that other types of dynamics exist beyond payoff-based dynamics, e.g., imitative dynamics, in which agents agent copy the action of some other nodes and switch to that strategy with a probability that depends on the payoff of that action."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
